{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leaf_classification_using_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NegiArvind/LeafClassification/blob/master/leaf_classification_using_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M5uK5Jx0bCn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For google colab \n",
        "path=\"/content/drive/My Drive/LeafClassification/\"\n",
        "\n",
        "# For system\n",
        "# path=\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xaYPeaQBZvx5",
        "colab_type": "code",
        "outputId": "680b5777-9d98-4442-9925-3477d761e87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/LeafClassfication\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "ls: cannot access '/content/drive/My Drive/LeafClassfication': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mtsPr_Lfp4iz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !sudo apt-get install python-skimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0h0GuZdbYEqe",
        "colab_type": "code",
        "outputId": "8c8658da-eac7-40e5-b8b3-dd488736161a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from skimage.transform import resize,rotate,rescale\n",
        "from PIL import Image\n",
        "import h5py\n",
        "from tensorflow.python.framework import ops\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "from scipy import ndimage\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import pickle as pkl\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6FhvB_uYEq0",
        "colab_type": "code",
        "outputId": "25922fe0-5caa-4f92-84dc-8e8f1ddedfbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x=np.random.rand(4)\n",
        "np.random.seed(1)\n",
        "y=np.random.rand(4)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01]\n",
            "[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iCWce3txqzIe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip freeze"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSlwPy0vAD_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTN_sIY7YEsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(y,n_labels):\n",
        "    return np.eye(n_labels)[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAdTHSvvmthn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes=os.listdir(path+\"leaf_dataset\")\n",
        "n_class=len(classes)\n",
        "samples_per_class=16\n",
        "image_width=32 # width of image\n",
        "image_height=32 # height of image\n",
        "n_channel=1 # number of channels\n",
        "m=n_class*samples_per_class # Number of samples))\n",
        "\n",
        "train_ratio=0.7\n",
        "validation_ratio=0.2\n",
        "test_ratio=0.1\n",
        "\n",
        "ntraining_samples=int(samples_per_class*train_ratio)\n",
        "nvalidation_samples=int(samples_per_class*validation_ratio)\n",
        "ntest_samples=samples_per_class-ntraining_samples-nvalidation_samples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1bKqWG7TkWMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_augumented_images(image):\n",
        "    \n",
        "#     print(image.shape)\n",
        "    augumented_images=[]\n",
        "#     augumented_images=np.zeros((6,50,50,1))\n",
        "    augumented_images.append(image)\n",
        "#     augumented_images[0]=image\n",
        "#     img=rotate(image, angle=90, mode='reflect',resize=True)\n",
        "#     plt.imshow(img.reshape(image_height,image_width))\n",
        "#     print(img.shape)\n",
        "\n",
        "    # Rotation\n",
        "    rot90=rotate(image, angle=90, mode='reflect',resize=True)\n",
        "    rot90=cv2.resize(rot90, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)\n",
        "#     print(augumented_images[1].shape)\n",
        "    augumented_images.append(rot90)\n",
        "    \n",
        "    rot180=rotate(image, angle=180, mode='reflect',resize=True)\n",
        "    rot180=cv2.resize(rot180, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)\n",
        "    \n",
        "#     print(augumented_images[2].shape)\n",
        "    augumented_images.append(rot180)\n",
        "  \n",
        "    rot270=rotate(image, angle=270, mode='reflect',resize=True)\n",
        "    rot270=cv2.resize(rot270, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)\n",
        "#     print(augumented_images[3].shape)\n",
        "    augumented_images.append(rot270)\n",
        "  \n",
        "  \n",
        "    #Scaling\n",
        "    scale_out=rescale(image, scale=2.0, mode='constant')\n",
        "#     print(\"Scale out\",scale_out.shape)\n",
        "    augumented_images.append(cv2.resize(scale_out, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel))\n",
        "#     augumented_images[4]=cv2.resize(scale_out, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)\n",
        "#     print(augumented_images[4].shape)\n",
        "    scale_in=rescale(image, scale=0.5, mode='constant')\n",
        "#     print(\"Scale in\",scale_in.shape)\n",
        "    augumented_images.append(cv2.resize(scale_in, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel))\n",
        "#     augumented_images[5]=cv2.resize(scale_in, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)\n",
        "#     print(augumented_images[5].shape)\n",
        "#     augumented_images.append((rescale(img, scale=0.5, mode='constant')).cv2.resize(image, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel))\n",
        "    \n",
        "# scale_in = skimage.transform.rescale(img, scale=0.5, mode='constant')\n",
        "    #\n",
        "#     print(type(augumented_images[0]))\n",
        "    return augumented_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbIqsq0dCjuc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing purpose\n",
        "\n",
        "# l=[]\n",
        "# image=img.imread(\"/content/drive/My Drive/LeafClassification/leaf_dataset/Acer_Campestre/Acer_Campestre_01.ab.jpg\")\n",
        "# image=cv2.resize(image, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)/255\n",
        "# p=get_augumented_images(image)\n",
        "# # print(\"p\",type(p),p.shape)\n",
        "# l.extend(p)\n",
        "# l=np.asarray(l)\n",
        "# print(l.dtype)\n",
        "# print(l.shape)\n",
        "# !ls \"/content/drive/My Drive/LeafClassification/leaf_dataset/Acer_Campestre/Acer_Campestre_01.ab.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l7yZfh9cJ20I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dataset(isSave):\n",
        "    \n",
        "    # isSave will be true when we want to save the data in pkl and will be false when \n",
        "    # we want to get the data from pkl\n",
        "    if isSave:\n",
        "        classes=os.listdir(path+\"leaf_dataset\")\n",
        "\n",
        "        n_class=len(classes)\n",
        "        samples_per_class=16\n",
        "        image_width=32 # width of image\n",
        "        image_height=32 # height of image\n",
        "        n_channel=1 # number of channels\n",
        "        m=n_class*samples_per_class # Number of samples))\n",
        "\n",
        "        train_ratio=0.7\n",
        "        validation_ratio=0.2\n",
        "        test_ratio=0.1\n",
        "\n",
        "        ntraining_samples=int(samples_per_class*train_ratio)\n",
        "        nvalidation_samples=int(samples_per_class*validation_ratio)\n",
        "        ntest_samples=samples_per_class-ntraining_samples-nvalidation_samples\n",
        "        \n",
        "\n",
        "        print(\"m\",m)\n",
        "        print(\"classes\",len(classes))\n",
        "        print(\"ntraining_samples\",ntraining_samples)\n",
        "        print(\"nvalidation_samples\",nvalidation_samples)\n",
        "        print(\"ntest_samples\",ntest_samples)\n",
        "\n",
        "#         x_train_set=np.zeros((ntraining_samples*n_class,image_width,image_height,n_channel),dtype=np.float32)\n",
        "#         x_validation_set=np.zeros((nvalidation_samples*n_class,image_width,image_height,n_channel),dtype=np.float32)\n",
        "#         x_test_set=np.zeros((ntest_samples*n_class,image_width,image_height,n_channel),dtype=np.float32)\n",
        "\n",
        "#         y_train_set=np.zeros((ntraining_samples*n_class),dtype=int)\n",
        "#         y_validation_set=np.zeros((nvalidation_samples*n_class),dtype=int)\n",
        "#         y_test_set=np.zeros((ntest_samples*n_class),dtype=int)\n",
        "        \n",
        "        x_train_set=[]\n",
        "        y_train_set=[]\n",
        "        x_validation_set=[]\n",
        "        y_validation_set=[]\n",
        "        x_test_set=[]\n",
        "        y_test_set=[]\n",
        "\n",
        "        train_count=0\n",
        "        test_count=0\n",
        "        validation_count=0\n",
        "        \n",
        "        print(\"Data is Saving .....\")\n",
        "\n",
        "        for count,class_name in enumerate(classes):\n",
        "            class_name_path=path+\"leaf_dataset/\"+class_name+\"/\"\n",
        "\n",
        "            images=os.listdir(class_name_path);\n",
        "            random.shuffle(images)\n",
        "\n",
        "            train_images=images[:ntraining_samples]\n",
        "            validation_images=images[ntraining_samples:ntraining_samples+nvalidation_samples]\n",
        "            test_images=images[ntraining_samples+nvalidation_samples:]\n",
        "\n",
        "#             print(\"train_images\",train_images)\n",
        "#             print(\"validation_images\",validation_images)\n",
        "#             print(\"test_images\",test_images)\n",
        "\n",
        "            # Filling training set\n",
        "            for image_name in train_images:\n",
        "    #             print(\"image_name\",image_name)\n",
        "                image=img.imread(class_name_path+image_name)\n",
        "    #             print(image.shape)\n",
        "                image=cv2.resize(image, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)/255\n",
        "    #             print(image.shape)\n",
        "                augumented_images=get_augumented_images(image)\n",
        "#                 x_train_set[train_count]=image\n",
        "#                 y_train_set[train_count]=count\n",
        "                x_train_set.extend(augumented_images)\n",
        "                temp=[count]*len(augumented_images)\n",
        "                y_train_set.extend(temp)\n",
        "#                 train_count+=1\n",
        "\n",
        "            # Filling validation set\n",
        "            for image_name in validation_images:\n",
        "    #             print(\"image_name\",image_name)\n",
        "                image=img.imread(class_name_path+image_name)\n",
        "    #             print(image.shape)\n",
        "                image=cv2.resize(image, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)/255\n",
        "    #             print(image.shape)\n",
        "#                 x_validation_set[validation_count]=image\n",
        "#                 y_validation_set[validation_count]=count\n",
        "                x_validation_set.append(image)\n",
        "                y_validation_set.append(count)\n",
        "#                 validation_count+=1\n",
        "\n",
        "            # Filling test set\n",
        "            for image_name in test_images:\n",
        "    #             print(\"image_name\",image_name)\n",
        "                image=img.imread(class_name_path+image_name,)\n",
        "    #             print(image.shape)\n",
        "                image=cv2.resize(image, dsize=(image_height,image_width), interpolation=cv2.INTER_CUBIC).reshape(image_height,image_width,n_channel)/255\n",
        "    #             print(image.shape)\n",
        "#                 x_test_set[test_count]=image\n",
        "#                 y_test_set[test_count]=count\n",
        "                x_test_set.append(image)\n",
        "                y_test_set.append(count)\n",
        "#                 test_count+=1\n",
        "\n",
        "#         print(len(classes))\n",
        "    #     np.set_printoptions(threshold=np.inf)\n",
        "#         print(\"y_train_set\",y_train_set.shape,y_train_set)\n",
        "#         print(\"y_validation_set\",y_validation_set.shape,y_validation_set)\n",
        "#         print(\"y_test_set\",y_test_set.shape,y_test_set)\n",
        "#         print(\"Earlier\",x_train_set.dtype)\n",
        "        x_train_set=np.asarray(x_train_set,dtype=np.float32)\n",
        "        y_train_set=np.asarray(y_train_set)\n",
        "        x_validation_set=np.asarray(x_validation_set,dtype=np.float32)\n",
        "        y_validation_set=np.asarray(y_validation_set)\n",
        "        x_test_set=np.asarray(x_test_set,dtype=np.float32)\n",
        "        y_test_set=np.asarray(y_test_set)\n",
        "#         print(\"Later\",x_train_set.shape,y_train_set.shape,x_test_set.shape,y_test_set.shape)\n",
        "\n",
        "        x_train_set,y_train_set = shuffle(x_train_set,y_train_set, random_state=0) # This shuffles two array altoghether \n",
        "        x_validation_set,y_validation_set = shuffle(x_validation_set,y_validation_set, random_state=0)\n",
        "        x_test_set,y_test_set = shuffle(x_test_set,y_test_set, random_state=0)\n",
        "        \n",
        "        with open(path+\"xy_train_set.pkl\",'wb') as f:\n",
        "            print(\"train datatype\",x_train_set.dtype)\n",
        "            pkl.dump((x_train_set,y_train_set),f)\n",
        "            \n",
        "        with open(path+\"xy_validation_set.pkl\",'wb') as f:\n",
        "            print(\"validation type\",x_validation_set.dtype)\n",
        "            pkl.dump((x_validation_set,y_validation_set),f)\n",
        "            \n",
        "        with open(path+\"xy_test_set.pkl\",'wb') as f:\n",
        "            pkl.dump((x_test_set,y_test_set),f)\n",
        "            \n",
        "        with open(path+\"class_names.pkl\",'wb') as f:\n",
        "            pkl.dump(classes,f)\n",
        "        print(\"Data saved successfully\")\n",
        "        return x_train_set,y_train_set,x_validation_set,y_validation_set,x_test_set,y_test_set\n",
        "            \n",
        "    else:       \n",
        "        with open(path+\"xy_train_set.pkl\",'rb') as f:\n",
        "            x_train_set,y_train_set=pkl.load(f)\n",
        "        \n",
        "        with open(path+\"xy_validation_set.pkl\",'rb') as f:\n",
        "            x_validation_set,y_validation_set=pkl.load(f)\n",
        "            \n",
        "        with open(path+\"xy_test_set.pkl\",'rb') as f:\n",
        "            x_test_set,y_test_set=pkl.load(f)\n",
        "        \n",
        "        print(\"Data loaded successfully\")\n",
        "        return x_train_set,y_train_set,x_validation_set,y_validation_set,x_test_set,y_test_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7eKIQ5fNYEso",
        "colab_type": "code",
        "outputId": "a9128085-4201-4181-9fae-60f45808dbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train_set,y_train_set,x_validation_set,y_validation_set,x_test_set,y_test_set=load_dataset(isSave=False)\n",
        "# print(x_train_set,y_train_set,x_validation_set,y_validation_set,x_test_set,y_test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5WALkZAYEs1",
        "colab_type": "code",
        "outputId": "ee670960-ba11-46d3-edfa-ce88a3107780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "m,image_height,image_width,n_channel=x_train_set.shape\n",
        "with open(path+\"class_names.pkl\",'rb') as f:\n",
        "  class_names=pkl.load(f)\n",
        "print(class_names)\n",
        "n_labels=100\n",
        "print(m,image_height,image_width,n_channel,n_labels,x_train_set.dtype,x_test_set.dtype,x_validation_set.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Lithocarpus_Edulis', 'Salix_Intergra', 'Populus_Adenopoda', 'Quercus_Phillyraeoides', 'Quercus_Shumardii', 'Quercus_Phellos', 'Betula_Pendula', 'Quercus_Rubra', 'Quercus_Pubescens', 'Betula_Austrosinensis', 'Quercus_Pontica', 'Populus_Nigra', 'Alnus_Maximowiczii', 'Quercus_Kewensis', 'Celtis_Koraiensis', 'Quercus_Texana', 'Acer_Palmatum', 'Arundinaria_Simonii', 'Quercus_Semecarpifolia', 'Cornus_Chinensis', 'Fagus_Sylvatica', 'Alnus_Sieboldiana', 'Morus_Nigra', 'Cotinus_Coggygria', 'Acer_Rufinerve', 'Eucalyptus_Neglecta', 'Acer_Capillipes', 'Phildelphus', 'Castanea_Sativa', 'Quercus_Cerris', 'Quercus_Coccinea', 'Sorbus_Aria', 'Salix_Fragilis', 'Pterocarya_Stenoptera', 'Olea_Europaea', 'Quercus_Hartwissiana', 'Magnolia_Heptapeta', 'Zelkova_Serrata', 'Quercus_Rhysophylla', 'Quercus_Agrifolia', 'Acer_Circinatum', 'Tilia_Platyphyllos', 'Quercus_Castaneifolia', 'Quercus_Nigra', 'Magnolia_Salicifolia', 'Callicarpa_Bodinieri', 'Ginkgo_Biloba', 'Alnus_Rubra', 'Alnus_Cordata', 'Quercus_Suber', 'Prunus_X_Shmittii', 'Ilex_Aquifolium', 'Acer_Mono', 'Cornus_Controversa', 'Liquidambar_Styraciflua', 'Quercus_Brantii', 'Quercus_Infectoria_sub', 'Quercus_Ellipsoidalis', 'Prunus_Avium', 'Ulmus_Bergmanniana', 'Rhododendron_x_Russellianum', 'Quercus_Chrysolepis', 'Quercus_Pyrenaica', 'Viburnum_x_Rhytidophylloides', 'Quercus_Imbricaria', 'Quercus_Trojana', 'Quercus_Alnifolia', 'Tilia_Tomentosa', 'Quercus_Ilex', 'Viburnum_Tinus', 'Crataegus_Monogyna', 'Quercus_Greggii', 'Acer_Campestre', 'Populus_Grandidentata', 'Quercus_Variabilis', 'Acer_Pictum', 'Cytisus_Battandieri', 'Quercus_Dolicholepis', 'Quercus_Crassifolia', 'Quercus_Coccifera', 'Quercus_x_Hispanica', 'Eucalyptus_Glaucescens', 'Liriodendron_Tulipifera', 'Acer_Rubrum', 'Quercus_Canariensis', 'Tilia_Oliveri', 'Quercus_Afares', 'Eucalyptus_Urnigera', 'Lithocarpus_Cleistocarpus', 'Acer_Platanoids', 'Cercis_Siliquastrum', 'Quercus_Crassipes', 'Ilex_Cornuta', 'Quercus_x_Turneri', 'Quercus_Palustris', 'Acer_Opalus', 'Alnus_Viridis', 'Acer_Saccharinum', 'Cornus_Macrophylla', 'Quercus_Vulcanica']\n",
            "6600 32 32 1 100 float32 float32 float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6wRMpL_YEtD",
        "colab_type": "code",
        "outputId": "8215233e-dc45-4416-ea03-d28f11f82744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train_set[0].reshape(image_height,image_width),cmap=plt.get_cmap('gray'))\n",
        "plt.title(class_names[np.argmax(y_train_set[0])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Lithocarpus_Edulis')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D3Acv1amgPIi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# datagen=ImageDataGenerator(rotation_range=40,\n",
        "#         width_shift_range=0.2,\n",
        "#         height_shift_range=0.2,\n",
        "#         shear_range=0.2,\n",
        "#         zoom_range=0.2,\n",
        "#         horizontal_flip=True,\n",
        "#         fill_mode='nearest')\n",
        "# datagen.fit(x_train_set)\n",
        "# count=0;\n",
        "# for x_batch,y_batch in datagen.flow(x_train_set,y_train_set,batch_size=32,save_to_dir=path+\"/Augumented/\", save_prefix=class_names[np.argmax(y_batch[0])], save_format='png'):\n",
        "# #   print(x_batch,y_batch)\n",
        "#   print(x_batch.shape,y_batch.shape,type(x_batch))\n",
        "#   count=count+32\n",
        "# #   plt.imshow(x_batch[0],cmap=plt.get_cmap('gray'))\n",
        "# #   plt.title(y_batch[0])\n",
        "# #   plt.imshow(x_batch[1],cmap=plt.get_cmap('gray'))\n",
        "# #   plt.title(y_batch[1])\n",
        "# #   plt.imshow(x_batch[2])\n",
        "# #   plt.title(y_batch[2])\n",
        "# #   plt.imshow(x_batch[3])\n",
        "# #   plt.title(y_batch[3])\n",
        "# #   plt.imshow(x_batch[4])\n",
        "# #   plt.title(y_batch[4])\n",
        "# print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHOPFzpOYEtR",
        "colab_type": "code",
        "outputId": "370e5279-75b0-44cd-b3de-75b22f7de961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying hot_encoder to every y array of training set,validation test and test set\n",
        "\n",
        "print(type(y_train_set))\n",
        "y_train_set=one_hot_encode(y_train_set,n_labels)\n",
        "y_validation_set=one_hot_encode(y_validation_set,n_labels)\n",
        "y_test_set=one_hot_encode(y_test_set,n_labels)\n",
        "print(y_train_set.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(6600, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5TkKp_A4YEtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=tf.placeholder(tf.float32,shape=[None,image_height,image_width,n_channel])\n",
        "y=tf.placeholder(tf.float32,shape=[None,n_labels])\n",
        "drop_prob=tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoB8URO2YEtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_weight(shape):\n",
        "    init_random_weight=tf.truncated_normal(shape,stddev=1.0)\n",
        "    return tf.Variable(init_random_weight)\n",
        "\n",
        "def initialize_bias(shape):\n",
        "    init_random_bias=tf.constant(0.1,shape=shape) # initialize all the weights with 0.1\n",
        "    return tf.Variable(init_random_bias)\n",
        "\n",
        "def conv2d(x,w):\n",
        "    return tf.nn.conv2d(x,w,strides=[1,2,2,1],padding=\"SAME\")\n",
        "\n",
        "def max_pooling_2d(x):\n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "\n",
        "def convolution_layer(input_x,shape):\n",
        "    w=initialize_weight(shape)\n",
        "    b=initialize_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x,w)+b)\n",
        "\n",
        "def normal_full_layer(input_layer,size):\n",
        "    input_size=int(input_layer.get_shape()[1]) # getting the number of neuron unit in next layer\n",
        "    w=initialize_weight([input_size,size])\n",
        "    b=initialize_bias([size])\n",
        "    return tf.matmul(input_layer,w)+b\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "IyBOhw1NYEtz",
        "colab_type": "code",
        "outputId": "fef97fc1-9b74-4b9b-f34c-87536f4bb77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Model\n",
        "print(x)\n",
        "\n",
        "# Layer 1\n",
        "convo_1=convolution_layer(x,shape=[5,5,1,32])\n",
        "max_pooling_1=tf.nn.max_pool(convo_1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "\n",
        "# Layer 2\n",
        "convo_2=convolution_layer(max_pooling_1,shape=[5,5,32,32])\n",
        "max_pooling_2=tf.nn.max_pool(convo_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "\n",
        "# Layer 3\n",
        "convo_3=convolution_layer(max_pooling_2,shape=[5,5,32,64])\n",
        "max_pooling_3=tf.nn.max_pool(convo_3,ksize=[1,2,2,1],strides=[1,1,1,1],padding=\"SAME\")\n",
        "last_shape=max_pooling_3.get_shape()\n",
        "print(last_shape)\n",
        "\n",
        "\n",
        "convo_4=convolution_layer(max_pooling_3,shape=[5,5,64,64])\n",
        "max_pooling_4=tf.nn.max_pool(convo_4,ksize=[1,2,2,1],strides=[1,1,1,1],padding=\"SAME\")\n",
        "last_shape=max_pooling_4.get_shape()\n",
        "print(last_shape)\n",
        "\n",
        "#Flattening\n",
        "convo_4_flat=tf.reshape(max_pooling_4,[-1,last_shape[-1]*last_shape[-2]*last_shape[-3]])\n",
        "\n",
        "#Fully connected layer 1\n",
        "full_layer_one=tf.nn.relu(tf.layers.batch_normalization(normal_full_layer(convo_4_flat,1024),axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True))\n",
        "\n",
        "# dropout\n",
        "full_one_dropout=tf.nn.dropout(full_layer_one,rate=1-drop_prob)\n",
        "\n",
        "\n",
        "#Fully connected layer 2\n",
        "full_layer_two=tf.nn.relu(tf.layers.batch_normalization(normal_full_layer(full_one_dropout,512),axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True))\n",
        "\n",
        "# dropout\n",
        "full_two_dropout=tf.nn.dropout(full_layer_two,rate=1-drop_prob)\n",
        "\n",
        "#Fully connected layer 3\n",
        "full_layer_three=tf.nn.relu(tf.layers.batch_normalization(normal_full_layer(full_two_dropout,256),axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True))\n",
        "\n",
        "# dropout\n",
        "full_three_dropout=tf.nn.dropout(full_layer_three,rate=1-drop_prob)\n",
        "\n",
        "\n",
        "#Final layer\n",
        "output_layer=normal_full_layer(full_three_dropout,n_labels)\n",
        "print(\"Output layer shape \",output_layer.get_shape())\n",
        "y_predict=output_layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder_9:0\", shape=(?, 50, 50, 1), dtype=float32)\n",
            "(?, 2, 2, 64)\n",
            "(?, 1, 1, 64)\n",
            "Output layer shape  (?, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rzy1tbRCYEt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=y_predict))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZTK6KSEYEuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=0.00001)\n",
        "train=optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1UtdlCaYEuT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init=tf.global_variables_initializer()\n",
        "saver=tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKTl4C62YEui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(i,batch_size):\n",
        "    batch_x=x_train_set[i:i+batch_size]\n",
        "    batch_y=y_train_set[i:i+batch_size]\n",
        "    return batch_x,batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIK4AlhJYEu8",
        "colab_type": "code",
        "outputId": "81e9ff87-9b21-471e-afbf-17eaafcc56da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2529
        }
      },
      "cell_type": "code",
      "source": [
        "steps=800\n",
        "batch_size=64\n",
        "train_accuracy_list=[]\n",
        "validation_accuracy_list=[]\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for j in range(steps):\n",
        "        print(\"Steps :\",j)\n",
        "        for i in range(0,m,batch_size):\n",
        "          batch_x,batch_y=next_batch(i,batch_size)\n",
        "#           i=(i+batch_size)/m\n",
        "          sess.run(train,feed_dict={x: batch_x,y:batch_y,drop_prob:1.0})\n",
        "          \n",
        "#           print(\"Step : \",j,\"Batch : \",i/batch_size,sep='\\t')\n",
        "        print(\"Train Accuracy\")\n",
        "        matches=tf.equal(tf.argmax(y_predict,1),tf.argmax(y,1))\n",
        "        accuracy=tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "        train_accuracy=sess.run(accuracy,feed_dict={x:x_train_set,y:y_train_set,drop_prob:1.0})\n",
        "        print(train_accuracy)\n",
        "        \n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        print(\"Validation Accuracy\")\n",
        "        validation_accuracy=sess.run(accuracy,feed_dict={x:x_validation_set,y:y_validation_set,drop_prob:1.0})\n",
        "        print(validation_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)\n",
        "        print(\"\\n\")\n",
        "    saved_model_path=saver.save(sess,path+\"TrainedModel/leaf_model.ckpt\")\n",
        "    print(\"Model saved in path \",saved_model_path)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps : 0\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 1\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 2\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 3\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 4\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 5\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 6\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 7\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 8\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 9\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 10\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 11\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 12\n",
            "Train Accuracy\n",
            "0.011363637\n",
            "Validation Accuracy\n",
            "0.01\n",
            "\n",
            "\n",
            "Steps : 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-0e4317eb6916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#           i=(i+batch_size)/m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#           print(\"Step : \",j,\"Batch : \",i/batch_size,sep='\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "18hES6DO_AJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0,steps),train_accuracy_list,'-',np.arange(0,steps),validation_accuracy_list,'-')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6sSoF4tYEwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing the model on test set\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess,path+\"TrainedModel/leaf_model.ckpt\")\n",
        "    print(\"Train Acccuracy\")\n",
        "    print(sess.run(accuracy,feed_dict={x:x_test_set,y:y_test_set,drop_prob:1.0}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udzvBBnhAC0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uJsFAZgXYeA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## New Approach or New Model"
      ]
    },
    {
      "metadata": {
        "id": "SHvy5G19Mu9Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "image_size = 32\n",
        "num_channels = 1\n",
        "batch_size = 64\n",
        "patch_size = 5\n",
        "depth = 64\n",
        "num_hidden = 256\n",
        "\n",
        "num_labels = 100\n",
        "reg_parameter = 0.001\n",
        "learn_rate = 0.01\n",
        "keep_prob = 0.9\n",
        "\n",
        "\n",
        "class Network():\n",
        "    def __init__(self, is_training):\n",
        "        # Input data.\n",
        "        self.data = tf.placeholder(shape=[None, image_size, image_size, 1], dtype=tf.float32, name='input')\n",
        "        self.labels = tf.placeholder(shape=[None,num_labels], dtype=tf.int32)\n",
        "#         self.label_oh = slim.layers.one_hot_encoding(self.labels, num_labels)\n",
        "\n",
        "        ### Variables.\n",
        "        # Weights\n",
        "        self.layer1_weights = tf.Variable(tf.truncated_normal(\n",
        "            [patch_size, patch_size, num_channels, depth], stddev=0.1),\n",
        "            name=\"layer1_weights\")\n",
        "        self.layer2_weights = tf.Variable(tf.truncated_normal(\n",
        "            [patch_size, patch_size, depth, depth], stddev=0.1),\n",
        "            name=\"layer2_weights\")\n",
        "        self.layer3_weights = tf.Variable(tf.truncated_normal(\n",
        "            [16 * image_size // 4 * image_size // 4 * depth, 512], stddev=0.1),\n",
        "            name=\"layer3_weights\")\n",
        "        self.layer4_weights = tf.Variable(tf.truncated_normal(\n",
        "            [512, num_hidden], stddev=0.1),name=\"layer3_weights\")\n",
        "        self.layer5_weights = tf.Variable(tf.truncated_normal(\n",
        "            [num_hidden, num_labels], stddev=0.1),\n",
        "            name=\"layer4_weights\")\n",
        "        \n",
        "\n",
        "        # Biases\n",
        "        # self.layer1_biases = tf.Variable(tf.zeros([depth]), name=\"layer1_biases\")\n",
        "        # self.layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]),\n",
        "        #     name=\"layer2_biases\")\n",
        "        # self.layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]),\n",
        "        #     name=\"layer3_biases\")\n",
        "        self.layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]),\n",
        "            name=\"layer5_biases\")\n",
        "\n",
        "        # Model\n",
        "        # 1st Convolution\n",
        "        self.conv = tf.nn.conv2d(self.data, self.layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
        "        print(\"Conv1\",self.conv.get_shape())\n",
        "        # batch normalize conv\n",
        "        self.conv = batch_norm_wrapper(self.conv, is_training)\n",
        "        print(\"batch1\",self.conv.get_shape())\n",
        "        # Relu activation of conv\n",
        "        self.layer1 = tf.nn.relu(self.conv)\n",
        "        print(\"relu1\",self.layer1.get_shape())\n",
        "        # Apply dropout\n",
        "        self.layer1 = tf.nn.dropout(self.layer1, keep_prob)\n",
        "        print(\"dropout1\",self.layer1.get_shape())\n",
        "        # 2nd Convolution\n",
        "        self.conv = tf.nn.conv2d(self.layer1, self.layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
        "        print(\"Conv2\",self.conv.get_shape())\n",
        "        \n",
        "        # batch normalize conv\n",
        "        self.conv = batch_norm_wrapper(self.conv, is_training)\n",
        "        print(\"batch2\",self.conv.get_shape())\n",
        "        \n",
        "        # Relu activation of conv\n",
        "        self.layer2 = tf.nn.relu(self.conv)\n",
        "        print(\"relu2\",self.layer2.get_shape())\n",
        "        \n",
        "        # Apply dropout\n",
        "        self.layer2 = tf.nn.dropout(self.layer2, keep_prob)\n",
        "        \n",
        "        print(\"dropout2\",self.layer2.get_shape())\n",
        "        \n",
        "        # Resize second layer output for fully connceted layer\n",
        "        self.shape = self.layer2.get_shape().as_list()\n",
        "        self.reshape = tf.reshape(self.layer2,\n",
        "            # tf.pack([tf.shape(self.data)[0], self.shape[1] * self.shape[2] * self.shape[3]]))\n",
        "            tf.stack([tf.shape(self.data)[0], self.shape[1] * self.shape[2] * self.shape[3]]))\n",
        "        \n",
        "        # 1st fully connected layer\n",
        "        self.connected = tf.matmul(self.reshape, self.layer3_weights)\n",
        "        print(\"fully1\",self.connected.get_shape())\n",
        "        \n",
        "        # batch normalize\n",
        "        self.connected = batch_norm_wrapper(self.connected, is_training)\n",
        "        print(\"batch1\",self.connected.get_shape())\n",
        "        \n",
        "        # 1st fully connected layer with relu activation\n",
        "        self.layer3 = tf.nn.relu(self.connected)\n",
        "        print(\"relu\",self.layer3.get_shape())\n",
        "        # Apply dropout\n",
        "        self.layer3 = tf.nn.dropout(self.layer3, keep_prob)\n",
        "        print(\"dropout\",self.layer3.get_shape())\n",
        "        \n",
        "        # 2nd fully connected layer\n",
        "        self.connected = tf.matmul(self.layer3, self.layer4_weights)\n",
        "        print(\"full2\",self.connected.get_shape())\n",
        "        # batch normalize\n",
        "        self.connected = batch_norm_wrapper(self.connected, is_training)\n",
        "        print(\"batch\",self.connected.get_shape())\n",
        "        # 1st fully connected layer with relu activation\n",
        "        self.layer4 = tf.nn.relu(self.connected)\n",
        "        print(\"relu\",self.layer4.get_shape())\n",
        "        # Apply dropout\n",
        "        self.layer4 = tf.nn.dropout(self.layer4, keep_prob)\n",
        "        print(\"dropout\",self.layer4.get_shape())\n",
        "        \n",
        "        # 3rd fully connected layer\n",
        "        self.logits = tf.matmul(self.layer4, self.layer5_weights) + self.layer5_biases\n",
        "        print(\"output\",self.logits.get_shape())\n",
        "        # Softmax Predictions\n",
        "        self.probs = tf.nn.softmax(self.logits)\n",
        "        print(\"softmax\",self.probs.get_shape())\n",
        "\n",
        "        # Training computation.\n",
        "        self.loss = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels))\n",
        "        # self.loss = tf.reduce_mean(-tf.reduce_sum(\n",
        "            # self.label_oh * tf.log(self.probs) + 1e-10, reduction_indices=[1]))\n",
        "\n",
        "        # Optimizer.\n",
        "        self.trainer = tf.train.AdamOptimizer(learning_rate=learn_rate)\n",
        "        # minimization\n",
        "        self.update = self.trainer.minimize(self.loss)\n",
        "\n",
        "\n",
        "# Batch Norm Wrapper inspired by http://r2rt.com/implementing-batch-normalization-in-tensorflow.html\n",
        "\n",
        "def batch_norm_wrapper(inputs, is_training, decay=0.999, epsilon=1e-3):\n",
        "    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n",
        "    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n",
        "    sample_mean = tf.Variable(tf.zeros(inputs.get_shape()[1:]), trainable=False)\n",
        "    sample_variance = tf.Variable(tf.ones(inputs.get_shape()[1:]), trainable=False)\n",
        "\n",
        "    if is_training:\n",
        "        batch_mean, batch_variance = tf.nn.moments(inputs, [0])\n",
        "        train_mean = tf.assign(sample_mean,\n",
        "            sample_mean * decay + batch_mean * (1 - decay))\n",
        "        train_variance = tf.assign(sample_variance,\n",
        "            sample_variance * decay + batch_variance * (1 - decay))\n",
        "        with tf.control_dependencies([train_mean, train_variance]):\n",
        "            return tf.nn.batch_normalization(inputs,\n",
        "                batch_mean, batch_variance, beta, scale, epsilon)\n",
        "    else:\n",
        "        return tf.nn.batch_normalization(inputs,\n",
        "            sample_mean, sample_variance, beta, scale, epsilon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8swswMXfEtB-",
        "colab_type": "code",
        "outputId": "093daa9e-a15b-4198-8a92-f6cd5ad45baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "mainN = Network(is_training=True)\n",
        "# mainN.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv1 (?, 32, 32, 64)\n",
            "batch1 (?, 32, 32, 64)\n",
            "relu1 (?, 32, 32, 64)\n",
            "dropout1 (?, 32, 32, 64)\n",
            "Conv2 (?, 32, 32, 64)\n",
            "batch2 (?, 32, 32, 64)\n",
            "relu2 (?, 32, 32, 64)\n",
            "dropout2 (?, 32, 32, 64)\n",
            "fully1 (?, 512)\n",
            "batch1 (?, 512)\n",
            "relu (?, 512)\n",
            "dropout (?, 512)\n",
            "full2 (?, 256)\n",
            "batch (?, 256)\n",
            "relu (?, 256)\n",
            "dropout (?, 256)\n",
            "output (?, 100)\n",
            "softmax (?, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "clgV7WG9PajD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(predictions, labels):\n",
        "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/predictions.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZ0crf1JN1k5",
        "colab_type": "code",
        "outputId": "8d8678f8-ebff-479a-dd29-f65b8dfb9709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75447
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import argparse\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "# from model_helpers import *\n",
        "# from data_helpers import *\n",
        "# from network import *\n",
        "\n",
        "# Setting the training parameters\n",
        "\n",
        "# Number of possible actions\n",
        "actions = 100\n",
        "# How many experience traces to use for each training step.\n",
        "batch_size = 64\n",
        "# Number of training steps\n",
        "num_steps = 3001\n",
        "\n",
        "# The path to save our model to.\n",
        "# path = path+\"./cnn\"\n",
        "train_dataset=x_train_set\n",
        "train_labels=y_train_set\n",
        "valid_dataset=x_validation_set\n",
        "valid_labels=y_validation_set\n",
        "losses = []\n",
        "train_accuracies = []\n",
        "validation_accuracies=[]\n",
        "def train(load_model=False):\n",
        "    # load data\n",
        "#     images, labels = load_data()\n",
        "\n",
        "    # convert to training and validation sets\n",
        "#     x_train, x_valid, train_labels, valid_labels = split_data(images, labels)\n",
        "#     train_dataset = reformat(x_train)\n",
        "#     valid_dataset = reformat(x_valid)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    mainN = Network(is_training=True)\n",
        "\n",
        "    init = tf.initialize_all_variables()\n",
        "\n",
        "    saver = tf.train.Saver(max_to_keep=5)\n",
        "\n",
        "    # Make list to store losses, accuracies\n",
        "#     losses = []\n",
        "#     accuracies = []\n",
        "    # Make a path for our model to be saved in.\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        if load_model is True:\n",
        "            print('Loading Model...')\n",
        "            ckpt = tf.train.get_checkpoint_state(path)\n",
        "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "            print('Model Successfully Loaded')\n",
        "        else:\n",
        "            sess.run(init)\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
        "            batch_labels = train_labels[offset:(offset + batch_size)]\n",
        "            \n",
        "            _, lossA, yP, LO = sess.run([mainN.update, mainN.loss, mainN.probs, mainN.labels],\n",
        "                feed_dict={mainN.data: batch_data, mainN.labels: batch_labels})\n",
        "#             losses.append(lossA)\n",
        "#             accuracies.append(accuracy(yP, LO))\n",
        "            if (step % 5 == 0):\n",
        "                minibatch_loss=(step, lossA)\n",
        "                print('Minibatch loss at step %d: %f ' % minibatch_loss)\n",
        "                batch_train_accuracy=accuracy(yP, LO)\n",
        "                print('Minibatch accuracy: %.1f%% ' %batch_train_accuracy )\n",
        "                losses.append(lossA)\n",
        "                train_accuracies.append(batch_train_accuracy)\n",
        "                yP, LO = sess.run([mainN.probs, mainN.labels],\n",
        "                    feed_dict={mainN.data: valid_dataset, mainN.labels: valid_labels})\n",
        "                validation_accuracy=accuracy(yP, LO)\n",
        "                print('Validation accuracy: %.1f%%' % validation_accuracy)\n",
        "                validation_accuracies.append(validation_accuracy)\n",
        "                saver.save(sess, path+'/model-'+str(step)+'.cptk')\n",
        "                print(\"Saved Model\")\n",
        "        yP, LO = sess.run([mainN.probs, mainN.labels],\n",
        "            feed_dict={mainN.data: valid_dataset, mainN.labels: valid_labels})\n",
        "        print('Validation accuracy: %.1f%%' % accuracy(yP, LO))\n",
        "        saver.save(sess, path+'/model-'+str(step)+'.cptk')\n",
        "        print(\"Saved Model\")\n",
        "        plt.figure(1)\n",
        "        plt.title('Training Loss')\n",
        "        plt.plot(range(len(losses)), losses)\n",
        "        plt.figure(2)\n",
        "        plt.title('Training Accuracies')\n",
        "        plt.plot(range(len(validation_accuracies)), validation_accuracies,'-',range(len(train_accuracies)),train_accuracies,'.')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def validate():\n",
        "    tf.reset_default_graph()\n",
        "    mainN = Network(is_training=False)\n",
        "\n",
        "    saver = tf.train.Saver(max_to_keep=5)\n",
        "\n",
        "    # load data\n",
        "    images, labels = load_data()\n",
        "\n",
        "    # convert to training and validation sets\n",
        "    x_train, x_valid, train_labels, valid_labels = split_data(images, labels)\n",
        "    valid_dataset = reformat(x_valid)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        print('Loading Model...')\n",
        "        ckpt = tf.train.get_checkpoint_state(path)\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "        print('Model Loaded!')\n",
        "\n",
        "        yP, LO = sess.run([mainN.probs, mainN.label_oh],\n",
        "            feed_dict={mainN.data: valid_dataset, mainN.labels: valid_labels})\n",
        "        print('Validation accuracy: %.1f%%' % accuracy(yP, LO))\n",
        "\n",
        "\n",
        "def test():\n",
        "    tf.reset_default_graph()\n",
        "    mainN = Network(is_training=False)\n",
        "\n",
        "    saver = tf.train.Saver(max_to_keep=5)\n",
        "\n",
        "    # load data\n",
        "    images, image_id, species = load_test_data()\n",
        "\n",
        "    test_dataset = reformat(images)\n",
        "    test_dataset.astype(float)\n",
        "    with tf.Session() as sess:\n",
        "        print('Loading Model...')\n",
        "        ckpt = tf.train.get_checkpoint_state(path)\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "        print('Model Loaded!')\n",
        "\n",
        "        yP = sess.run([mainN.probs], feed_dict={mainN.data: test_dataset})\n",
        "        np.save('testProbs', yP)\n",
        "        print('Completed processing {} test images'.format(str(image_id.shape[0])))\n",
        "        write_results_to_file(species, image_id, yP)\n",
        "\n",
        "\n",
        "def writeResults():\n",
        "    # load data\n",
        "    images, image_id, species = load_test_data()\n",
        "    # load saved results\n",
        "    probs = np.load('testProbs.npy')\n",
        "    write_results_to_file(species, image_id, probs)\n",
        "\n",
        "\n",
        "def main():\n",
        "    train(False)\n",
        "#     parser = argparse.ArgumentParser(description=\"Train or run leaf classifier\")\n",
        "#     parser.add_argument(\"-m\", \"--mode\", help=\"Train / Run / Validate\", required=True)\n",
        "#     parser.add_argument(\"-l\", \"--load\", help=\"Load previously trained weights? True/False\")\n",
        "#     args = vars(parser.parse_args())\n",
        "#     if args['mode'] == 'Train':\n",
        "#         if args['load']:\n",
        "#             if args['load'] == 'True':\n",
        "#                 train(load_model=True)\n",
        "#         else:\n",
        "#             train(load_model=False)\n",
        "#     elif args['mode'] == 'Test':\n",
        "#         test()\n",
        "#     elif args['mode'] == 'Validate':\n",
        "#         validate()\n",
        "#     elif args['mode'] == 'Write':\n",
        "#         writeResults()\n",
        "#     else:\n",
        "#         print(':p Invalid Mode.')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minibatch loss at step 0: 5.327022 \n",
            "Minibatch accuracy: 0.0% \n",
            "Validation accuracy: 6.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5: 4.639953 \n",
            "Minibatch accuracy: 6.2% \n",
            "Validation accuracy: 14.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 10: 4.340534 \n",
            "Minibatch accuracy: 3.1% \n",
            "Validation accuracy: 15.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 15: 3.580505 \n",
            "Minibatch accuracy: 17.2% \n",
            "Validation accuracy: 19.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 20: 3.098834 \n",
            "Minibatch accuracy: 17.2% \n",
            "Validation accuracy: 24.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 25: 3.382073 \n",
            "Minibatch accuracy: 14.1% \n",
            "Validation accuracy: 29.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 30: 3.318089 \n",
            "Minibatch accuracy: 23.4% \n",
            "Validation accuracy: 28.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 35: 2.981353 \n",
            "Minibatch accuracy: 20.3% \n",
            "Validation accuracy: 32.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 40: 2.520767 \n",
            "Minibatch accuracy: 34.4% \n",
            "Validation accuracy: 37.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 45: 2.538171 \n",
            "Minibatch accuracy: 25.0% \n",
            "Validation accuracy: 36.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 50: 2.386362 \n",
            "Minibatch accuracy: 34.4% \n",
            "Validation accuracy: 38.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 55: 2.465308 \n",
            "Minibatch accuracy: 34.4% \n",
            "Validation accuracy: 45.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 60: 2.542113 \n",
            "Minibatch accuracy: 32.8% \n",
            "Validation accuracy: 43.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 65: 2.104803 \n",
            "Minibatch accuracy: 48.4% \n",
            "Validation accuracy: 43.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 70: 1.951291 \n",
            "Minibatch accuracy: 51.6% \n",
            "Validation accuracy: 49.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 75: 2.089220 \n",
            "Minibatch accuracy: 32.8% \n",
            "Validation accuracy: 45.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 80: 2.101078 \n",
            "Minibatch accuracy: 31.2% \n",
            "Validation accuracy: 45.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 85: 1.697125 \n",
            "Minibatch accuracy: 48.4% \n",
            "Validation accuracy: 46.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 90: 1.655640 \n",
            "Minibatch accuracy: 50.0% \n",
            "Validation accuracy: 49.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 95: 1.555321 \n",
            "Minibatch accuracy: 56.2% \n",
            "Validation accuracy: 49.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 100: 1.796533 \n",
            "Minibatch accuracy: 50.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 105: 1.539252 \n",
            "Minibatch accuracy: 53.1% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 110: 2.205875 \n",
            "Minibatch accuracy: 39.1% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 115: 1.374877 \n",
            "Minibatch accuracy: 50.0% \n",
            "Validation accuracy: 49.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 120: 1.600705 \n",
            "Minibatch accuracy: 50.0% \n",
            "Validation accuracy: 49.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 125: 1.420846 \n",
            "Minibatch accuracy: 56.2% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 130: 1.572061 \n",
            "Minibatch accuracy: 53.1% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 135: 1.455713 \n",
            "Minibatch accuracy: 51.6% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 140: 1.607411 \n",
            "Minibatch accuracy: 53.1% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 145: 1.361002 \n",
            "Minibatch accuracy: 51.6% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 150: 1.279979 \n",
            "Minibatch accuracy: 56.2% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 155: 0.948666 \n",
            "Minibatch accuracy: 65.6% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 160: 0.993057 \n",
            "Minibatch accuracy: 73.4% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 165: 1.202983 \n",
            "Minibatch accuracy: 57.8% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 170: 1.276674 \n",
            "Minibatch accuracy: 57.8% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 175: 1.115168 \n",
            "Minibatch accuracy: 65.6% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 180: 1.072518 \n",
            "Minibatch accuracy: 67.2% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 185: 1.203609 \n",
            "Minibatch accuracy: 68.8% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 190: 1.024010 \n",
            "Minibatch accuracy: 70.3% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 195: 1.140077 \n",
            "Minibatch accuracy: 62.5% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 200: 0.785706 \n",
            "Minibatch accuracy: 75.0% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 205: 1.082986 \n",
            "Minibatch accuracy: 67.2% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 210: 0.911573 \n",
            "Minibatch accuracy: 70.3% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 215: 1.100170 \n",
            "Minibatch accuracy: 65.6% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 220: 1.097425 \n",
            "Minibatch accuracy: 60.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 225: 0.794494 \n",
            "Minibatch accuracy: 76.6% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 230: 1.163496 \n",
            "Minibatch accuracy: 60.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 235: 0.912663 \n",
            "Minibatch accuracy: 73.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 240: 0.737722 \n",
            "Minibatch accuracy: 79.7% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 245: 0.933694 \n",
            "Minibatch accuracy: 67.2% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 250: 0.687350 \n",
            "Minibatch accuracy: 76.6% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 255: 0.858534 \n",
            "Minibatch accuracy: 75.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 260: 1.372876 \n",
            "Minibatch accuracy: 56.2% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 265: 0.813210 \n",
            "Minibatch accuracy: 73.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 270: 0.733089 \n",
            "Minibatch accuracy: 71.9% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 275: 0.551148 \n",
            "Minibatch accuracy: 79.7% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 280: 0.602413 \n",
            "Minibatch accuracy: 82.8% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 285: 0.735693 \n",
            "Minibatch accuracy: 73.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 290: 0.530033 \n",
            "Minibatch accuracy: 78.1% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 295: 0.557771 \n",
            "Minibatch accuracy: 84.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 300: 0.719260 \n",
            "Minibatch accuracy: 76.6% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 305: 0.822746 \n",
            "Minibatch accuracy: 75.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 310: 0.607000 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 315: 0.761904 \n",
            "Minibatch accuracy: 73.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 320: 0.673218 \n",
            "Minibatch accuracy: 76.6% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 325: 0.647556 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 330: 0.557388 \n",
            "Minibatch accuracy: 82.8% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 335: 0.545415 \n",
            "Minibatch accuracy: 82.8% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 340: 0.489839 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 345: 0.543487 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 350: 0.364876 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 355: 0.329935 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 360: 0.556690 \n",
            "Minibatch accuracy: 84.4% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 365: 0.287055 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 370: 0.611466 \n",
            "Minibatch accuracy: 82.8% \n",
            "Validation accuracy: 61.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 375: 0.347204 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 380: 0.544268 \n",
            "Minibatch accuracy: 76.6% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 385: 0.508870 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 390: 0.551596 \n",
            "Minibatch accuracy: 78.1% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 395: 0.388883 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 400: 0.208943 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 405: 0.514193 \n",
            "Minibatch accuracy: 79.7% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 410: 0.376990 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 415: 0.464569 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 420: 0.402618 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 425: 0.388038 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 430: 0.432954 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 435: 0.310690 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 440: 0.276181 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 445: 0.308403 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 450: 0.489299 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 455: 0.313894 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 460: 0.254587 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 465: 0.368057 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 470: 0.304118 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 475: 0.370531 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 480: 0.136541 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 485: 0.307727 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 490: 0.406293 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 495: 0.503143 \n",
            "Minibatch accuracy: 81.2% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 500: 0.291765 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 505: 0.417317 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 510: 0.221926 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 515: 0.362248 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 520: 0.217952 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 525: 0.236714 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 530: 0.379604 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 535: 0.317287 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 540: 0.287531 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 545: 0.195873 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 550: 0.225978 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 555: 0.236075 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 560: 0.436144 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 565: 0.179801 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 570: 0.193235 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 575: 0.237105 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 580: 0.068903 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 585: 0.233380 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 590: 0.270084 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 595: 0.221172 \n",
            "Minibatch accuracy: 89.1% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 600: 0.346200 \n",
            "Minibatch accuracy: 87.5% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 605: 0.416060 \n",
            "Minibatch accuracy: 85.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 610: 0.141012 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 615: 0.257056 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 620: 0.148316 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 61.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 625: 0.162296 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 630: 0.237865 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 635: 0.219685 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 640: 0.144577 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 645: 0.232041 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 650: 0.125122 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 655: 0.193425 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 660: 0.190126 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 665: 0.206579 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 670: 0.102936 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 675: 0.176517 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 680: 0.140540 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 685: 0.119689 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 690: 0.168473 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 695: 0.198417 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 700: 0.119218 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 705: 0.126065 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 710: 0.138036 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 715: 0.137410 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 720: 0.163262 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 725: 0.160147 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 730: 0.135045 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 735: 0.181242 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 740: 0.101686 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 745: 0.175020 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 750: 0.060306 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 755: 0.148331 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 760: 0.149066 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 765: 0.099911 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 770: 0.041679 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 775: 0.220383 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 780: 0.064456 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 785: 0.143203 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 790: 0.073721 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 795: 0.047466 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 800: 0.220644 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 805: 0.081849 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 810: 0.034601 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 815: 0.115445 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 820: 0.065530 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 825: 0.094415 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 830: 0.067939 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 835: 0.118104 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 840: 0.034234 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 845: 0.062474 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 850: 0.170409 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 855: 0.147982 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 860: 0.148361 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 865: 0.098783 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 870: 0.077579 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 875: 0.184374 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 61.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 880: 0.330220 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 885: 0.061049 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 890: 0.202799 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 895: 0.169037 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 900: 0.112264 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 905: 0.140172 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 910: 0.130663 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 915: 0.371200 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 920: 0.226437 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 925: 0.109494 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 930: 0.125620 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 935: 0.165199 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 940: 0.047746 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 945: 0.187812 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 950: 0.083073 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 955: 0.022121 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 960: 0.183991 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 965: 0.089576 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 970: 0.187931 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 975: 0.263236 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 980: 0.038076 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 985: 0.089014 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 990: 0.096849 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 995: 0.233368 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1000: 0.092587 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1005: 0.082237 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1010: 0.150938 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1015: 0.213290 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1020: 0.023817 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1025: 0.040892 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1030: 0.103689 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1035: 0.135441 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1040: 0.119937 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1045: 0.113846 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1050: 0.072714 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1055: 0.065749 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1060: 0.031823 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1065: 0.074144 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1070: 0.071600 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1075: 0.030017 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1080: 0.021012 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1085: 0.011783 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1090: 0.028881 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1095: 0.121835 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1100: 0.031861 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1105: 0.084409 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1110: 0.026345 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1115: 0.054232 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1120: 0.046531 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1125: 0.036283 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1130: 0.118831 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1135: 0.052313 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1140: 0.131536 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1145: 0.065918 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1150: 0.151728 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1155: 0.014915 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1160: 0.064065 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1165: 0.068712 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1170: 0.090632 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1175: 0.047207 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1180: 0.222501 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1185: 0.114541 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1190: 0.007152 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1195: 0.114217 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1200: 0.183816 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1205: 0.047510 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1210: 0.121952 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1215: 0.059504 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1220: 0.166002 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1225: 0.073308 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1230: 0.183144 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1235: 0.136356 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1240: 0.061371 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1245: 0.024337 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1250: 0.066027 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1255: 0.034196 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1260: 0.162064 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1265: 0.135390 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1270: 0.018039 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1275: 0.097771 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1280: 0.182101 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1285: 0.119590 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1290: 0.054131 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1295: 0.088909 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1300: 0.224200 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1305: 0.093850 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1310: 0.051300 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1315: 0.057950 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1320: 0.049953 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1325: 0.129174 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1330: 0.097705 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1335: 0.068929 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1340: 0.032769 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1345: 0.050709 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1350: 0.031515 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1355: 0.041824 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1360: 0.021440 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1365: 0.134032 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1370: 0.144241 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1375: 0.120351 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1380: 0.049331 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1385: 0.021371 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1390: 0.129847 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1395: 0.082784 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1400: 0.060561 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1405: 0.038486 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1410: 0.041169 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1415: 0.041531 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1420: 0.031741 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 61.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1425: 0.239760 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 62.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1430: 0.059687 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1435: 0.011948 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1440: 0.173096 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1445: 0.051715 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1450: 0.022016 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1455: 0.036553 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1460: 0.062718 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1465: 0.016739 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1470: 0.175308 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1475: 0.123899 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1480: 0.215916 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1485: 0.096770 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1490: 0.031074 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1495: 0.051390 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1500: 0.083176 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1505: 0.026950 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1510: 0.067918 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 61.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1515: 0.013666 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1520: 0.126525 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1525: 0.014130 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1530: 0.058701 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1535: 0.023712 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1540: 0.171245 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1545: 0.075890 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1550: 0.135339 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1555: 0.018499 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1560: 0.021138 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1565: 0.176460 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1570: 0.117766 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1575: 0.091289 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1580: 0.085435 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1585: 0.095755 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1590: 0.013857 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1595: 0.035435 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1600: 0.143945 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1605: 0.096111 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1610: 0.083457 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1615: 0.074298 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1620: 0.204542 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1625: 0.013739 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1630: 0.145655 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1635: 0.071555 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1640: 0.078538 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1645: 0.213715 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1650: 0.104021 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1655: 0.083077 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1660: 0.033878 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1665: 0.067991 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1670: 0.293161 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1675: 0.035925 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1680: 0.090284 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1685: 0.045065 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1690: 0.107515 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1695: 0.067672 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1700: 0.016276 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1705: 0.097594 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1710: 0.208727 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1715: 0.086431 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1720: 0.016608 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1725: 0.031818 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1730: 0.035673 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1735: 0.075670 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1740: 0.091761 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1745: 0.029243 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1750: 0.049802 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1755: 0.074901 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1760: 0.217012 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1765: 0.046663 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1770: 0.028786 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1775: 0.013327 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1780: 0.344311 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1785: 0.012300 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1790: 0.008714 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1795: 0.101913 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1800: 0.022346 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1805: 0.006108 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1810: 0.096819 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1815: 0.028678 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1820: 0.025939 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1825: 0.026745 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1830: 0.048139 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1835: 0.022204 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1840: 0.017462 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1845: 0.026390 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1850: 0.066014 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1855: 0.041985 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1860: 0.013464 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1865: 0.012215 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1870: 0.038718 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1875: 0.002022 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1880: 0.002025 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1885: 0.005063 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1890: 0.053329 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1895: 0.004147 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1900: 0.020595 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1905: 0.003375 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1910: 0.033418 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1915: 0.016670 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1920: 0.015058 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1925: 0.135116 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1930: 0.016461 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1935: 0.030480 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1940: 0.012670 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1945: 0.045652 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1950: 0.088331 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1955: 0.022229 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 1960: 0.148992 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 1965: 0.008256 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1970: 0.125451 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1975: 0.022257 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1980: 0.019548 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1985: 0.009140 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1990: 0.004022 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 1995: 0.018513 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2000: 0.003994 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2005: 0.070586 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2010: 0.004206 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2015: 0.064915 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2020: 0.006079 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2025: 0.012153 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2030: 0.007662 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2035: 0.007613 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2040: 0.005455 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2045: 0.008623 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2050: 0.131491 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2055: 0.061692 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2060: 0.006624 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2065: 0.005719 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2070: 0.041003 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2075: 0.075402 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2080: 0.003636 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2085: 0.024141 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2090: 0.017705 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2095: 0.002130 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2100: 0.007646 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2105: 0.010721 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2110: 0.009977 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2115: 0.001511 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2120: 0.052945 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2125: 0.007646 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2130: 0.009802 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2135: 0.005784 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2140: 0.014591 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2145: 0.025453 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2150: 0.023041 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2155: 0.044764 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2160: 0.065647 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2165: 0.004111 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2170: 0.061008 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2175: 0.043547 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2180: 0.027767 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2185: 0.004160 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2190: 0.110949 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2195: 0.109617 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2200: 0.038296 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2205: 0.022233 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2210: 0.022188 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2215: 0.038961 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2220: 0.013426 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2225: 0.074154 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2230: 0.002753 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2235: 0.002682 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2240: 0.040004 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2245: 0.068154 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2250: 0.003972 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2255: 0.023264 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2260: 0.058360 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2265: 0.007160 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2270: 0.025585 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2275: 0.008854 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2280: 0.017741 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2285: 0.156208 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2290: 0.017285 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2295: 0.152707 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2300: 0.012720 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2305: 0.059345 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2310: 0.071502 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2315: 0.017739 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2320: 0.105356 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2325: 0.005301 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2330: 0.015290 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2335: 0.007006 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2340: 0.034821 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2345: 0.013429 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2350: 0.026166 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2355: 0.052616 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2360: 0.003802 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2365: 0.016252 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2370: 0.079720 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2375: 0.004001 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2380: 0.004638 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2385: 0.008663 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2390: 0.025394 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2395: 0.012941 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2400: 0.085454 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2405: 0.025849 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 47.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2410: 0.014126 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2415: 0.093697 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 50.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2420: 0.039317 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 51.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2425: 0.002817 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2430: 0.102944 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 48.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2435: 0.023860 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2440: 0.120163 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2445: 0.154472 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2450: 0.106881 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2455: 0.128686 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2460: 0.131849 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2465: 0.108443 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2470: 0.090077 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2475: 0.041797 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2480: 0.078570 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2485: 0.093914 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2490: 0.296351 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2495: 0.005524 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2500: 0.078874 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2505: 0.022360 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2510: 0.027903 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2515: 0.094271 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2520: 0.104586 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2525: 0.061225 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2530: 0.145385 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2535: 0.072507 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2540: 0.094999 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2545: 0.014552 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2550: 0.304094 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2555: 0.099860 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2560: 0.010710 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2565: 0.081804 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2570: 0.242983 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2575: 0.045064 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2580: 0.163069 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2585: 0.049384 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2590: 0.010834 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2595: 0.029341 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2600: 0.197101 \n",
            "Minibatch accuracy: 90.6% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2605: 0.100547 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2610: 0.043130 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2615: 0.022139 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2620: 0.019559 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2625: 0.042036 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2630: 0.037134 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2635: 0.150756 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2640: 0.028842 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2645: 0.033985 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2650: 0.061112 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2655: 0.097872 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2660: 0.026899 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2665: 0.030108 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2670: 0.006463 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2675: 0.117434 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2680: 0.053469 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2685: 0.063070 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2690: 0.037829 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2695: 0.096483 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2700: 0.109313 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2705: 0.160581 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2710: 0.112975 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2715: 0.041023 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2720: 0.055227 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2725: 0.045623 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2730: 0.009257 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2735: 0.073198 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2740: 0.060253 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2745: 0.092779 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2750: 0.029538 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2755: 0.265207 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2760: 0.022928 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 62.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2765: 0.029665 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2770: 0.020135 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2775: 0.068800 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2780: 0.156081 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2785: 0.141906 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2790: 0.069393 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2795: 0.067538 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2800: 0.051579 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2805: 0.041360 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2810: 0.041440 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2815: 0.158512 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2820: 0.025785 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2825: 0.177965 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2830: 0.016270 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2835: 0.039848 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2840: 0.004439 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2845: 0.020569 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2850: 0.054548 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2855: 0.099110 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2860: 0.160049 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2865: 0.112608 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2870: 0.005883 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2875: 0.066868 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2880: 0.056673 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2885: 0.007954 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2890: 0.106174 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2895: 0.022924 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2900: 0.001001 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2905: 0.013795 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2910: 0.068951 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2915: 0.053140 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2920: 0.008024 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2925: 0.023546 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2930: 0.056299 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2935: 0.259947 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2940: 0.035161 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2945: 0.083280 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2950: 0.142964 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2955: 0.075446 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2960: 0.140024 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2965: 0.112309 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2970: 0.059256 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2975: 0.046252 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2980: 0.012043 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 2985: 0.045828 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 2990: 0.051050 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 2995: 0.045049 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3000: 0.009037 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3005: 0.091130 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3010: 0.011168 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3015: 0.048767 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3020: 0.001384 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3025: 0.017082 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3030: 0.004692 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3035: 0.086140 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3040: 0.028589 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3045: 0.028492 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3050: 0.007440 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3055: 0.036968 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3060: 0.030119 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3065: 0.015910 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3070: 0.030475 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3075: 0.046078 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3080: 0.043739 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3085: 0.028476 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3090: 0.011933 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3095: 0.007217 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3100: 0.007448 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3105: 0.001877 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3110: 0.054135 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3115: 0.011836 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3120: 0.002462 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3125: 0.099990 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3130: 0.014954 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3135: 0.000905 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3140: 0.007320 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3145: 0.017376 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3150: 0.009875 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3155: 0.018241 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3160: 0.061392 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3165: 0.001193 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 60.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3170: 0.053735 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3175: 0.027880 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3180: 0.554566 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3185: 0.101228 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3190: 0.077079 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3195: 0.011728 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3200: 0.185696 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3205: 0.014285 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3210: 0.011575 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3215: 0.081043 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3220: 0.005235 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3225: 0.022601 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3230: 0.084567 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3235: 0.407464 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3240: 0.036625 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3245: 0.003476 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3250: 0.017391 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3255: 0.005086 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3260: 0.006631 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3265: 0.017319 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3270: 0.104381 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3275: 0.019455 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3280: 0.005447 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3285: 0.015832 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3290: 0.148979 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3295: 0.043164 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3300: 0.014600 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3305: 0.042272 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3310: 0.004840 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3315: 0.005321 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3320: 0.011633 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3325: 0.003439 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3330: 0.001572 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3335: 0.056950 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3340: 0.060294 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3345: 0.016998 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3350: 0.005026 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3355: 0.009230 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3360: 0.002405 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3365: 0.027808 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3370: 0.020360 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3375: 0.001904 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3380: 0.019058 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3385: 0.001024 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3390: 0.005838 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3395: 0.018560 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3400: 0.001319 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3405: 0.026172 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 61.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3410: 0.006321 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3415: 0.003837 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3420: 0.052242 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3425: 0.010892 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3430: 0.001830 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3435: 0.024280 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3440: 0.019839 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3445: 0.001194 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3450: 0.006432 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3455: 0.000795 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3460: 0.002058 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 60.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3465: 0.002634 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3470: 0.001269 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3475: 0.004274 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3480: 0.001483 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3485: 0.000798 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3490: 0.006033 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3495: 0.005048 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3500: 0.001106 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3505: 0.002113 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3510: 0.009331 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3515: 0.075163 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3520: 0.008787 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3525: 0.058323 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3530: 0.024448 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3535: 0.004541 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3540: 0.010578 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3545: 0.012843 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3550: 0.039939 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3555: 0.046438 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3560: 0.149138 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3565: 0.027621 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3570: 0.006439 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3575: 0.006806 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3580: 0.027766 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3585: 0.005497 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3590: 0.000579 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3595: 0.010154 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3600: 0.015135 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3605: 0.015649 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3610: 0.002548 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3615: 0.001242 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3620: 0.039893 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 62.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3625: 0.022525 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3630: 0.031354 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3635: 0.008909 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3640: 0.080241 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3645: 0.070483 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3650: 0.008593 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3655: 0.020842 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3660: 0.167057 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3665: 0.035175 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 60.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3670: 0.012445 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3675: 0.026103 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3680: 0.022239 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3685: 0.114623 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3690: 0.017496 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3695: 0.139496 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3700: 0.141547 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3705: 0.083198 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3710: 0.167528 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3715: 0.020406 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3720: 0.060344 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3725: 0.049857 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3730: 0.024124 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3735: 0.010014 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3740: 0.018491 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3745: 0.033209 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3750: 0.007938 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3755: 0.058461 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3760: 0.093099 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3765: 0.115289 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3770: 0.024378 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 49.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3775: 0.110705 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3780: 0.077144 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3785: 0.041382 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3790: 0.103429 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3795: 0.012370 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3800: 0.002127 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3805: 0.053674 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3810: 0.017000 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3815: 0.074081 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3820: 0.012360 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3825: 0.044377 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3830: 0.061850 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3835: 0.280942 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3840: 0.047549 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3845: 0.010566 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3850: 0.000952 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3855: 0.075633 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3860: 0.094141 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3865: 0.008339 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3870: 0.113526 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3875: 0.148370 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3880: 0.017858 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3885: 0.068116 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3890: 0.079927 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3895: 0.084487 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3900: 0.006771 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3905: 0.066276 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3910: 0.083758 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3915: 0.079264 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3920: 0.170915 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3925: 0.009099 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3930: 0.002204 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3935: 0.006583 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3940: 0.029521 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3945: 0.005963 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3950: 0.004621 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3955: 0.042958 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3960: 0.001728 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3965: 0.007261 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3970: 0.084365 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3975: 0.065634 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3980: 0.033779 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 3985: 0.053487 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 3990: 0.086157 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 3995: 0.096771 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4000: 0.002980 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4005: 0.030167 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4010: 0.027924 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4015: 0.075689 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4020: 0.171455 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4025: 0.022206 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4030: 0.003030 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4035: 0.086464 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4040: 0.074338 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4045: 0.003989 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4050: 0.028433 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4055: 0.023355 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4060: 0.004370 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4065: 0.004424 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4070: 0.045180 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4075: 0.009409 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4080: 0.003120 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4085: 0.307056 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4090: 0.010679 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4095: 0.006372 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 50.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4100: 0.005809 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4105: 0.149098 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4110: 0.024461 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4115: 0.033491 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4120: 0.085769 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4125: 0.004427 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4130: 0.005923 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4135: 0.007685 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4140: 0.092785 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4145: 0.023115 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4150: 0.029945 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4155: 0.004378 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4160: 0.003646 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4165: 0.017597 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4170: 0.004998 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4175: 0.022316 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4180: 0.001197 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4185: 0.006083 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4190: 0.006278 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4195: 0.031834 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4200: 0.003461 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4205: 0.058294 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4210: 0.089758 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4215: 0.002056 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4220: 0.009123 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4225: 0.017113 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4230: 0.101958 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4235: 0.008327 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4240: 0.071135 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4245: 0.021008 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4250: 0.019680 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4255: 0.018294 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4260: 0.004227 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4265: 0.004501 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4270: 0.059135 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4275: 0.006845 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4280: 0.002617 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4285: 0.043867 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4290: 0.107940 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4295: 0.002866 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4300: 0.049447 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4305: 0.000611 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4310: 0.023087 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4315: 0.001217 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4320: 0.015919 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4325: 0.000408 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4330: 0.001844 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4335: 0.002530 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4340: 0.003152 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4345: 0.001550 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4350: 0.107275 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4355: 0.075267 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4360: 0.002383 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4365: 0.042009 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4370: 0.044802 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4375: 0.003424 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4380: 0.164329 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4385: 0.032149 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4390: 0.003985 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4395: 0.105907 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4400: 0.019874 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4405: 0.033085 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4410: 0.005977 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4415: 0.010835 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4420: 0.028872 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4425: 0.002415 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4430: 0.005515 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4435: 0.004570 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4440: 0.019171 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4445: 0.039409 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4450: 0.024960 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4455: 0.008478 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4460: 0.167375 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4465: 0.064696 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4470: 0.024480 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4475: 0.102836 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4480: 0.077771 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4485: 0.023431 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4490: 0.049175 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4495: 0.000168 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4500: 0.038787 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4505: 0.096428 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4510: 0.030109 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4515: 0.000930 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4520: 0.005009 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4525: 0.044848 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4530: 0.002048 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4535: 0.033848 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4540: 0.012317 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4545: 0.015874 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4550: 0.000405 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4555: 0.024349 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4560: 0.000898 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4565: 0.001103 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4570: 0.025489 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4575: 0.003891 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4580: 0.001129 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4585: 0.005020 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4590: 0.002893 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4595: 0.001550 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4600: 0.067202 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4605: 0.010331 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4610: 0.008370 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4615: 0.000703 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4620: 0.003149 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4625: 0.007335 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4630: 0.002565 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4635: 0.012170 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4640: 0.001918 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4645: 0.021089 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4650: 0.171314 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4655: 0.007715 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4660: 0.001026 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4665: 0.028591 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4670: 0.001352 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4675: 0.025732 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4680: 0.033072 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4685: 0.001464 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4690: 0.011288 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4695: 0.091395 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4700: 0.055498 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4705: 0.003288 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4710: 0.007257 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4715: 0.052702 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4720: 0.089622 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4725: 0.001855 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4730: 0.007836 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4735: 0.010788 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4740: 0.009410 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4745: 0.002420 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4750: 0.001390 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4755: 0.082803 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4760: 0.011157 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4765: 0.000595 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4770: 0.026521 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4775: 0.013756 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4780: 0.002029 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4785: 0.004212 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4790: 0.000982 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4795: 0.004355 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4800: 0.012874 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4805: 0.007625 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4810: 0.003129 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4815: 0.020533 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4820: 0.008314 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4825: 0.006534 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4830: 0.044043 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4835: 0.016422 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4840: 0.002585 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4845: 0.003443 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4850: 0.044920 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4855: 0.002020 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4860: 0.076674 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4865: 0.010648 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4870: 0.063887 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4875: 0.035242 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4880: 0.083558 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4885: 0.030471 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4890: 0.024266 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4895: 0.054918 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4900: 0.014703 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4905: 0.025676 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4910: 0.041545 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4915: 0.062440 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4920: 0.126741 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 59.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4925: 0.023201 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4930: 0.122103 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4935: 0.006803 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4940: 0.009142 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4945: 0.009535 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 50.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4950: 0.083679 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4955: 0.015565 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4960: 0.027187 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4965: 0.034303 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 4970: 0.013266 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 58.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4975: 0.002211 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4980: 0.029261 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 4985: 0.100280 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4990: 0.055923 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 4995: 0.007724 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5000: 0.070026 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5005: 0.073938 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5010: 0.064953 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5015: 0.054806 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5020: 0.008535 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 49.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5025: 0.017578 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5030: 0.055955 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5035: 0.017761 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5040: 0.006880 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5045: 0.022134 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5050: 0.086239 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5055: 0.014103 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5060: 0.002631 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5065: 0.002014 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5070: 0.006485 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5075: 0.002947 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5080: 0.150981 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5085: 0.099479 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5090: 0.173864 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5095: 0.070286 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5100: 0.040910 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5105: 0.516777 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5110: 0.090007 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5115: 0.005074 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5120: 0.020889 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5125: 0.101849 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5130: 0.002001 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5135: 0.002462 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5140: 0.011751 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5145: 0.001913 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5150: 0.037344 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5155: 0.023625 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5160: 0.258179 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5165: 0.069336 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5170: 0.002914 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 50.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5175: 0.088627 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5180: 0.036587 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5185: 0.124214 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5190: 0.041611 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5195: 0.042027 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5200: 0.009194 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5205: 0.027561 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 50.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5210: 0.007829 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5215: 0.003443 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5220: 0.027507 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5225: 0.007596 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5230: 0.056526 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5235: 0.001634 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 57.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5240: 0.011035 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5245: 0.001994 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5250: 0.001085 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5255: 0.080200 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5260: 0.005879 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5265: 0.007764 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5270: 0.001203 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5275: 0.010437 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5280: 0.000721 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5285: 0.027463 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5290: 0.065646 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 57.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5295: 0.208676 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 59.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5300: 0.085661 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5305: 0.101474 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5310: 0.066202 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5315: 0.050182 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5320: 0.018037 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 55.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5325: 0.055109 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5330: 0.030805 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5335: 0.239390 \n",
            "Minibatch accuracy: 92.2% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5340: 0.006443 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5345: 0.008635 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5350: 0.007273 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5355: 0.004442 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5360: 0.006011 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5365: 0.000669 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 50.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5370: 0.008167 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5375: 0.011105 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 55.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5380: 0.015489 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5385: 0.012862 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5390: 0.006789 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5395: 0.059654 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5400: 0.008732 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5405: 0.330362 \n",
            "Minibatch accuracy: 93.8% \n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5410: 0.185751 \n",
            "Minibatch accuracy: 95.3% \n",
            "Validation accuracy: 58.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5415: 0.076946 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 52.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5420: 0.041300 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5425: 0.013932 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5430: 0.003275 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5435: 0.006235 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5440: 0.000855 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5445: 0.006655 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5450: 0.001486 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5455: 0.003860 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5460: 0.004607 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5465: 0.014298 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 53.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5470: 0.076642 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 53.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5475: 0.028505 \n",
            "Minibatch accuracy: 98.4% \n",
            "Validation accuracy: 53.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5480: 0.091687 \n",
            "Minibatch accuracy: 96.9% \n",
            "Validation accuracy: 54.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5485: 0.002782 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 52.0%\n",
            "Saved Model\n",
            "Minibatch loss at step 5490: 0.023080 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 54.3%\n",
            "Saved Model\n",
            "Minibatch loss at step 5495: 0.005575 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 51.7%\n",
            "Saved Model\n",
            "Minibatch loss at step 5500: 0.003009 \n",
            "Minibatch accuracy: 100.0% \n",
            "Validation accuracy: 56.0%\n",
            "Saved Model\n",
            "Validation accuracy: 54.0%\n",
            "Saved Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcFOWdx/HPb3ou7kMGRJEMKBGD\nt8QjGu94x1xmE7MaszHBVzbJGpNNgm5M1DXRROOVeOEZjVfWqElQREFAkcvhkENuGGA4Z4AZmLuP\nZ//o6maO7umegaGrZ77v12teTFdVd/+K6vn2U089VWXOOUREJHvkZLoAERFpHwW3iEiWUXCLiGQZ\nBbeISJZRcIuIZBkFt4hIllFwi6+ZWcDMqs1s+IFcViSbmcZxy4FkZtVNHvYEGoCw9/gG59wLB7+q\n/WdmdwLDnHPfyXQtIrmZLkC6Fudc79jvZlYKfM85NyXZ8maW65wLHYzaRLoKdZXIQWVmd5rZK2b2\nkpntBa4xszPMbI6ZVZrZVjN7yMzyvOVzzcyZWbH3+K/e/ElmttfMZpvZiPYu682/1MxWmVmVmf3J\nzD40s+90YJ3GmNkMr/4lZnZ5k3lXmNly7/3LzOwmb/pgM3vLe84uM3u/o/+n0v0ouCUTvgK8CPQD\nXgFCwI3AIOBM4BLghjae/y3gVmAgsBH43/Yua2aDgb8BP/fedz1wantXxMzygYnAm0ARcBPwipkd\n5S3yDHC9c64PcDwww5v+c2Cd95xDgV+1972l+1JwSybMdM79yzkXcc7VOec+cs7Ndc6FnHPrgAnA\nOW08/1XnXIlzLgi8AJzYgWWvABY55/7hzbsfqOjAupwJ5AP3OOeCXrfQJOCb3vwg8Bkz6+Oc2+Wc\nW9Bk+mHAcOdco3NOLW5Jm4JbMmFT0wdmNtrM3jSzbWa2B7iDaCs4mW1Nfq8FeidbsI1lD2tah4se\npS9Lo/aWDgM2uuZH+TcAh3u/fwW4EthoZtPN7DRv+t3eclPNbK2Z/bwD7y3dlIJbMqHlUKbHgaXA\nUc65vsCvAevkGrYCw2IPzMzYF7btsQU4wnt+zHBgM4C3J3ElMJhol8rL3vQ9zrmbnHPFwJeBX5pZ\nW3sZInEKbvGDPkAVUGNmx9B2//aBMhE42cy+aGa5RPvYi1I8J2BmhU1+CoBZRPvof2ZmeWZ2PnAZ\n0X7uHmb2LTPr63XH7AUiAN77HukFfhXRIZORzllV6WoU3OIHPwOuIxpsjxM9YNmpnHPbgW8A9wE7\ngSOBhUTHnSdzDVDX5Gelc64B+CLwJaJ95A8B33LOrfaecx2wwesCut57DYCjgfeAauBD4EHn3AcH\nbAWlS9MJOCJEz7ok2u1xlQJU/E4tbum2zOwSM+vvdXncSnSkx7wMlyWSkoJburOziI6lLgcuBr7i\ndX2I+Jq6SkREsoxa3CIiWaZTLjI1aNAgV1xc3BkvLSLSJc2fP7/COZdqSCrQScFdXFxMSUlJZ7y0\niEiXZGYb0l1WXSUiIllGwS0ikmUU3CIiWUbBLSKSZRTcIiJZRsEtIpJlFNwiIlnGV8H90NTVzFhV\nnukyRER8zVfB/ej0tcxcreAWEWmLr4I7kGNEdM0rEZE2+Sq4zSCs5BYRaZOvgjva4lZwi4i0xV/B\nbaYWt4hICr4K7hy1uEVEUvJVcAfMiEQyXYWIiL/5KrhzDMJqcYuItMlfwZ1jRNTHLSLSprTugGNm\npcBeIAyEnHNjO6OYQI6pxS0ikkJ7bl12nnOuotMqQaNKRETS4auuEjNQg1tEpG3pBrcD3jGz+WY2\nLtECZjbOzErMrKS8vGPXGwnkqMUtIpJKusF9lnPuZOBS4IdmdnbLBZxzE5xzY51zY4uK0rrDfOti\nTH3cIiKppBXczrnN3r87gNeBUzujmIBGlYiIpJQyuM2sl5n1if0OXAQs7YxidK0SEZHU0hlVMgR4\n3cxiy7/onHu7M4oxM8LKbRGRNqUMbufcOuCEg1ALAUNdJSIiKfhqOKBGlYiIpOar4NaoEhGR1HwV\n3IEcwym4RUTa5KvgztEp7yIiKfkruHM0qkREJBVfBbdGlYiIpOav4NYJOCIiKfkquE193CIiKfkq\nuPMDOQTDuumkiEhbfBXceQEjqKOTIiJt8lVw5+eqxS0ikoqvgjsvkENjSMEtItIWXwV3fm4OjWpx\ni4i0yV/BrRa3iEhKvgruPI0qERFJyVfBnZ+bQ8ShsdwiIm3wVXDnBaLlqLtERCQ5XwV3fq4X3Oou\nERFJyl/BHTBALW4Rkbb4KrgDOdFy1MctIpKcz4I7+q9uXyYikpyvgjvHol0luia3iEhyvgruQE40\nuNVVIiKSnD+DW10lIiJJ+Sq41VUiIpKar4JbLW4RkdR8FdyxFrf6uEVEkvNVcMda3BGdfyMiklTa\nwW1mATNbaGYTO6uYXC+4Q0puEZGk2tPivhFY3lmFAOTEWtzq4xYRSSqt4DazYcDlwJOdWUwg3sfd\nme8iIpLd0m1xPwD8AkgaqWY2zsxKzKykvLy8Y8XETnnXwUkRkaRSBreZXQHscM7Nb2s559wE59xY\n59zYoqKiDhUTa3Grq0REJLl0WtxnAleaWSnwMnC+mf21M4rRKe8iIqmlDG7n3M3OuWHOuWLgm8B7\nzrlrOqUYnYAjIpKSv8Zx65R3EZGUctuzsHNuOjC9UypBXSUiIunwVYs7RwcnRURS8lVw72txZ7gQ\nEREf81lwR//VwUkRkeR8Fdy6HreISGq+Cm4dnBQRSc1XwR2/Hre6SkREkvJVcO+7HreCW0QkGV8G\nt1rcIiLJ+TO41eIWEUnKX8Gte06KiKTkq+DOUYtbRCQlXwV3QLcuExFJyV/BrVuXiYik5Kvgjt26\nTC1uEZHkfBXcOjgpIpKav4JbBydFRFLyVXCb1+JeW16d4UpERPzLV8EdM3Hx1kyXICLiW74MboA9\n9cFMlyAi4ku+De6tlfWZLkFExJd8G9y1jaFMlyAi4ku+De6QRpaIiCTk2+AO6vRJEZGEfBvcobBa\n3CIiifg3uCNqcYuIJOLf4FaLW0QkIf8Gtw5Oiogk5Nvg1sFJEZHEUga3mRWa2Twz+9jMlpnZ7Z1Z\n0I/PPwpQV4mISDLptLgbgPOdcycAJwKXmNnpnVXQNz57BKCDkyIiyeSmWsA554DY5fryvJ9Oaw7n\nBaLfJerjFhFJLK0+bjMLmNkiYAfwrnNubmcVlOtdk1tdJSIiiaUV3M65sHPuRGAYcKqZHdtyGTMb\nZ2YlZlZSXl7e4YJyvRa3Dk6KiCTWrlElzrlKYBpwSYJ5E5xzY51zY4uKijpcUF7Aa3Grq0REJKF0\nRpUUmVl/7/cewBeAFZ1VUK53x+CQWtwiIgmlPDgJDAX+YmYBokH/N+fcxE4rKEctbhGRtqQzqmQx\ncNJBqAWAnBwjx3RwUkQkGV+eOZkbyCGocdwiIgn5MrjzckwtbhGRJHwZ3LmBHB2cFBFJwp/BnWM6\nOCkikoQ/gzugrhIRkWT8Gdw5OjgpIpKML4M7Ty1uEZGkfBncuYEcXdZVRCQJfwa3hgOKiCTlz+AO\naFSJiEgy/gzunBzqGsPUB8OZLkVExHd8GdyLNlUye91ORt/6dqZLERHxHV8Gt4iIJOfL4L7rq8dl\nugQREd/yZXD3LczLdAkiIr7ly+CO3b5MRERa82Vw12k0iYhIUr4M7s8M7ZvpEkREfMuXwT1qSB/G\nnT0yfv9JERHZx5fBDVCYFyAUcTinMyhFRJrybXDHWtthnfouItKMf4PbG1mia5aIiDTn3+DOUXCL\niCTi2+AO5ERLC4cdL8/byOy1OzNckYiIP+RmuoBk8uJdJRHGv7YEgNK7L89kSSIivuDjFre6SkRE\nEvFtcKuPW0QkMR8Hd7S08X9fnOFKRET8xbfBXZgXAOCD1RUZrkRExF9SBreZHWFm08zsEzNbZmY3\nHozCehUEDsbbiIhknXRGlYSAnznnFphZH2C+mb3rnPukMwvrVeDbAS8iIhmVssXtnNvqnFvg/b4X\nWA4c3tmF9cxXi1tEJJF29XGbWTFwEjA3wbxxZlZiZiXl5eX7XVhewLfd7yIiGZV2OppZb+DvwE+c\nc3taznfOTXDOjXXOjS0qKtrvwvr31O3LREQSSSu4zSyPaGi/4Jx7rXNLihrcp5Abzh55MN5KRCSr\npDOqxICngOXOufs6v6R9igf1OphvJyKSFdJpcZ8JXAucb2aLvJ/LOrkuAN0BR0QkgZRj7pxzM4GM\nJGiu7vYuItKKr4duxE57FxGRfXydjHlqcYuItOLr4A6oxS0i0oqvk1F93CIirfk6uPPU4hYRacXX\nyTi4b0GmSxAR8R1fB/cInYAjItKKr4O75YWm/rFoM8FwJEPViIj4g6+Du6UbX17EEx+sy3QZIiIZ\nlVXBDbCzujHTJYiIZJTvg3vYgB7NHmuIoIh0d74P7g9+cV6zx7rwlIh0d74P7uhVZffRnXFEpLvL\nuhRUi1tEurusC+6WLXARke4m64K7IRjOdAkiIhmVVcFdkJtDQ6j1CTjvryrnnskrMlCRiMjBlxXB\n/cYPz+T3XzuOHvkBahtbt7i//fQ8Hp62NgOViYgcfFkR3Cce0Z9vfHY4h/TKZ2dNQ6bLERHJqKwI\n7phBvQvYXFlPZa3OnhSR7iurgvuQ3vl8vKmSE+94N9OliIhkTFYFd0FuIP67cy6DlYiIZE5WBXfT\nmwfPXb+r1XyFuYh0B1kW3PvK/eaEOa3mhyMKbhHp+rI2uAHW7NhL8fg3449DCm4R6QayKrjzc5uX\n+9O/fdzscURdJSLSDWRVcLe8wNTisqpmj9VVIiLdQVYFd6pLuiq4RaQ7SBncZva0me0ws6UHo6C2\n5KS4MqCCW0S6g3Ra3M8Cl3RyHWkJp+jDVnCLSHeQMridc+8DrQdNZ0A4Er0y4IXHDEk8XwcnRaQb\nOGB93GY2zsxKzKykvLz8QL1sM7tqggCcNLx/wvmhsIJbRLq+AxbczrkJzrmxzrmxRUVFB+plmynM\ni5Z74hGJg1vDAUWkO8jNdAHt8d8XHc1pIwbyuSMPSThffdwi0h1kVXD3KsjlkmOHJp2v4BaR7iCd\n4YAvAbOBo82szMyu7/yyOkYHJ0WkO0jZ4nbOXX0wCjkQQmHHx5sqOfrQPhTmBVI/QUQkC2XVmZOp\nlO2u40sPf8iv3sj4uUIiIp2mSwX3uopqAJa0uIaJiEhXkrXB/fz1p/LuTWc3m7ahohaAldv36qYK\nItJlZdWokqY+P6r1WPFXSjbFf69tDNOrIGtXT0QkqaxtccdMuPaUhNN3VutO8CLSNWV9cB97eL+E\n08urGw5yJSIiB0fWB/dh/Xuw5LaLWk1fuHF3BqoREel8WR/cAH0K81pN27Czlh176pm0ZGsGKhIR\n6TxdIrgT2VXTyDVPzeUHLyygPhjOdDkiIgdMlwzuk4b3p6K6gVXbo+O6l23Zk+GKpDtYuHE3u2t0\nUFw6X5cJ7j5Nhv6NPrQPc9fvu/fD1x6dxaZdtZkoS7qRrzwyi6ufmJPpMqQb6DLBPfuWCzhiYA/+\n48zihGO8v3D/jGaPN+2qZcaqzrnhg3Q/sRO+Vmzbm+FKJJUX5m6gePybNISytwu1y5yh0rsglw9+\ncT4AH5W2vtNafTBCfTDM6Fvf5t6vn8Atry2hMRyh9O7LD3ap0gXpksLZ4/53VwFQVRdkcJ/svBhd\nl2lxNzX2UwMSTr/plUUA3Dt5JY3hyMEsSbo4XVJYDqYuGdxmxtB+ha2mT1q6rdW0vfXR+1gWj3+T\nB6espiEUVn+4tJta3NnEov9k8SbrksENkGOWdJ5rssXGPTc/3j95/5RV3PTKIj7/h2kE1SKXdmgZ\n3OffO53HZqzNUDWSjlAWf9l22eBuI7fZvmff6fCz1+3k35+cG3/81pJoq7wh1PHg3lsf5OFpa9QK\n60Zabut1FTXcPWlFhqqRdGTz32eXDe6C3PRXbdbana2mNe5HcN87eSX3TF7JpKXZedbm5so6nptd\nmukysko2t966m1ijLpv3qrtscJ/z6cH79fyOBPdHpbsoHv9mfAx5dX1ov2rIlO88PY9f/2MZFVlw\noa5IxBHxQWg2rSHbrwVfWdvYLc423p8W91G3vMU1TfbUD7YuG9w3XzZ6v57fkeB+Z1m0myU2ltfv\nI1cWbark0emt+2F3eWf/RXwYQNUNIa6eMIf1FTUAjLzlLb7++OwMV9W8xR0M++P/raouSGVt+8/k\nPPGOd7nqsVmdUJE/xHpR92c7hSKOmWsqDkxBHdBlgzsvkMPJw/tz2oiB8Wn9e7a+GFUy2/fWt/s9\nY/3iuTnRj0Ys/F+et5ENO2va/Xqd7csPf8jv327dDxvblfRhbjNtxQ5mr9vJvZNXxqfN35DelSBX\nbd/LhPdTHzDcVlXPzNXt+6MMNwtuf3xhn3D7O5x4x7sdeu7SzV3/MhHhiKOuMcystZkL4I7qssEN\n8Np/nskrN5wRf/zWf32eIwb2SOu5X39sNk+8v65du+Gx3cvehdHzmhrDEeoaw4x/bQnn3DN9v8O7\nrjGcsJ5wxHHbP5excWfHhjEm27X3SwA1FdsLyMlpfvQ5dlJFW776yCx+99YKQinW68o/z+Sap9q3\nG9w0uEM+aXFLYvE+7kiEW15fwreemJtyCPBbS7by+sKyg1Bderp0cLd0WP8eTP3puYwc1Cut5X/7\n1nKufXoue+qb73LWNoYoHv8mxePf5JIH3o9Pj7W4K2ujY8MbQxF21uzrJz7nnun88+Mtbb7ntU/N\n5dO/mtRqeigc4Zhfv82dby5vNW/51j08O6uUH7+0gFA4wnef/YiSBGePxl7nvRXbeWDKvqDbXRvk\nyQ+iX1J/K9lEhXf3IL/s8jcVC+5Ai1FDD05dTX0w3Gb/cnVD9JhDqi6sHXuj26w9fdVNu0r83kUm\nUeGIY6XXrbnHO5+jpX99vIU1O6r5zxcWcNMrHx/M8trULYL74jFDuOGckQDk5+YwoFc+AHd++Vi+\netLhbT73wzU7Of626C5nTUOIuyetYOHGyvj8WH92XWOYmobmB3Re+WgTZ/1+WrNp//XSwjbf74PV\nFTSGIjw/u5TXFpSxcONunHM8OHU1AH+dsyHpc9eW17Bsyx7eW7GDG1+OniVaHwyzpz7I3HXRkTOP\nTF/Ld58t4YEpq+PPu/1fy7jzzeVMW7mDX7y6OD7djy3uWEktW9wAo299m0cS9Nm31BCMvsjmyjoW\nl1UmX64dxzmatrjfW7E97ecdbHvrg60OyoXCEaq8xkamD6w2hMLUNHTeQX3nXHw4cDAcIScnNj3x\n8j9+aSEX3jcj8cwM6hbB/fi1Y7n50mPij2Mf3GOG9uG+b5zIuzedzYXHDEn5OmN+M5nHZqxtNu47\n5phfv82U5c3/YLdWpd9P3hiK8ObifcMHb/3HMn76t4/5yiOzOP72d/jTe2taPad8b0OzP7TqhhBf\nevhDAHK9Julpv5vK8be9wzcmzKGkdBeLNrUOqrLddfEamkoV3NUNIZZtqUpzDZNbs6Oa7/2lhC2V\ndUmX+XhTJVOXb493FQXM2Jlg1MuLczcyfeWO+AWEKqob+MFf5ze73OofJq+ktKKGM+9+jyv//CFv\nLNzMkx+sa/Va1e0IkKZh+Mu/L2m1folqTceKbXvioRrz6vwyise/yd76IOOeK+H0301t8zWqG0Ks\n2r6X+mCY4257h7vear7XdvNrSzjhjneIRFyzvaytVcm3R1uenrmeL3ufQ4Dte+opHv9m/OB9W772\n6CzG/GZyh943HXdM/CT+ezjiMO9QZaK9pFRdakDGRjR1i+BuqV+P6EHKgtzoBWZGDenDE99OfNPh\ndFTVJd7NSua2fy4Doh+MhRt3EwpH+PSvJvHDFxckXH5vk2GFjeEIry8sY866nXz2t1O4/KGZCa9I\nVx+MHnRpWtsvXl3Meyt2tFo21sJpedJSsq6S+Rt2cd3T8/juMx9x+UMzm/WtLymratYNk46vPvIh\nU5Zv59IHP0i6zJce/pDr/1IS72rKMeOUO6e0Wm5zZR3feeYj7p60gr31QR6bvpZJS7fx4ryN8WVe\nmreRc++dHn/8k1cWJeyCGnvnFKYuT6/13NbQsgvvm8FF97+fdH5bLnngA74xofmomdgZmX96bw3v\nfLKdbXuiDYRIxCWs4+oJc7jo/vfjo4XeWLS52fz/mx/tu60Nhpt9WZ9x13sdqvmOiZ80ayDEPp/P\nt7G3GLM/B0WXlFXx8LQ1bTY4nvmwNP57KOyI7bi9t3xHqxE4NY2Jh0Q2/T+uaczMkN9uGdz3fv0E\n/ueyYxhzWN/4NGuSWn/+1knMvvn8tF/vhNvfadf7PzurlOkrd3Dfu6v4yiOz+O5fStr1/Jte+Tje\nh/3J1j389/+17nsb0reQbz3RfM9gXUXig6OxP6ymZ5QC3D1pOaUJnnPjy4uYsaqceV4NZ9+zrzvo\n6ifm8MCU1Ulbq/878RO+/PCHzVoqe7wvpqq6IH+aurrZ8s45Ji7ed1wgNgQr1VCsZz4s5bjb3uHJ\nmesBaEhjXPJNryxq1XVy96QV1DWGk/aB/mPRZrZV1Se9yNSDXpfUzg7cYKHOC46WX8yxT+qE95vv\nJXzn2Y848pa3OPsP0+LX4AFYsjm6V7TZ26OJNVig+YicmoZQq72uHXvqm617dUOIfyzaHA/mycu2\nccvr0T2MytpGvtfksxwL6jxv7++D1RWsK69m+db0wnlrVR31wXDaQ3O/+OeZ3DN5JX98ZxXOOV6c\nuzH+ZZXIQ+/t+6z9edoaxj03v9n8ZJ/hpl8MsUZVdUOo1Z5RZ+oyl3Vtj6I+BXz/7JFJ519x/GEA\nlN59Ob96YwlFvQu59LhDOaqoNyNveSut9/j9145rtcvc1A3PzyffO7vz/Q5cF3zOusQHH2MWl7W/\nC+M33p5A0/c4997pLL39YiprGxk2oCeQ+HICM1aVM6h3fvzg4fi/L+Y3XxxDUZ8CINpKKd1Zw1Ne\nkP59QRk983M57vB+zV7nj++u4scXjIqO6HGOu5KcNr65jW6VRFIdFAZ4feFmXl/YvDVaVRfk0gff\np9Tbq7j50tHccM6RQPSP9caXF3H0kD7c/qUxCV/z/nbufQCU7a5l0pJtXH780Fbz3l9Vzuod1a2m\nO+fin6ONu2pbfWlDdKQUQI/8ABt31nLuvdNo2kA/7XdTWzVYTv3dVIb2K2T2zRfQGIpwbJNujPV3\nXcYNz0fD7s4vHcs7n2xv1l146xtLufb0TzUL3vP/GO0vbno55WA4wqrtexlz2L7PQmlFTXyvaPjA\nnpw+ciCH9+/JjReOarbOf3pvDX+etobxl+w7b+OxGWvplR/gj++u4pbXlzD5J2czY9UOfvdW889S\n02NVAIs3Rx/XNYb56d8W8bWTh7X6P4zVG7O3PkR1Qyj+/3KwLhOdVnCb2SXAg0AAeNI5d3enVpVB\nZ4w8pNnjO798XLPH5x5dxPSViYP2hGH9+LisiqOH9OHfxh7RZnA3hCL7dT2Ugzn4P/ahfOLbY3lt\nQRl1ja3rvu7peQD0zI+25iYu3kqPvABnf7qINTuq2VJZF98lB/h5k4OgLT0/ZwO/fat118X5owcn\n7OpJR2kHh0rGRpjE3DVpBUcN7k0wHGGid0xi5fa9fHNC6jvfTFuxg+89V8Iz3/ksZ386erOP1xaU\nsbs2yPVnjYgv94O/LmDJ5iqem1Pa7Pm7axr55d8T/7+1/NKNtbITGTGoF3e/vZxEvTuvLdjcalrs\nWM0nLVrKTbuq5m/cnfQyE0sT1DLlk+1ccMxgzIy7J63gqZnref/n58Xnr6vY9+W0cVctG73herHg\nXrOjmjnrdnKfNwy0ad81RBsAMRc/kF43VX0wwt9KNsUP0H+QZCz/q00+x+vKq5m2smOfyf1hqY4i\nm1kAWAV8ASgDPgKuds59kuw5Y8eOdSUl7dv994PowYrEIxZiquqC3P7PZby2sPUHfO4tF7C5so6R\ng3rRv2c+xePfbDb/pOH9WbixkjNGHsLsda2vj9LSTy4c1Wz0x1WnDGPSkq1J+966umtP/1Ra/aTp\nGH1on5R3q7nwmCGtDjgfKIP7FNC7IDfefXX7lWO47nPFOOc48Y53Wx03ueb04fx1zsZEL3VQjBjU\nK362ajLf//wInvhgfbtet3/PvPjw2QnXnsK45+e3ufxj15zC3vpgm1/8nWnBrV/g5P/dd1LTf5xZ\nTL8eefG/05m/PC++Z9peZjbfOTc2rWXTCO4zgNuccxd7j28GcM7dlew52Rrc7dEQClOQG2DW2go+\nPaQP6ytq+GzxwGbL1DWGuf4vH/Gj84/imEP7snL7Xt5YuJnbrhzD/VNW8fiMaB/lF084jBsvGMWF\n983giyccxr8+3sLXTxnGXV89jh+9uJC3l23j2MP7MvHHnwegpHQXVz02mzOPOoS6xjA/OPcovv/c\nvv/v80cPpq4xHP9y6FOYy1lHDWLS0m3xMPrumSM45+gi8nKM656ZRzDsGNS7gHFnj2i1S+kX8265\ngH498zj6V28D8ML3Tms1wmdov0J65gfYUllPXTDMD849khsvGMXoW9+OL3P58UN58Bsn8m+Pz2bB\nxsTDAb//+RH88LyjOnzmYUcEcmy/r1j3uSMPSXjRNNnnti9+htv+lbTd2covLjmaP7y9MvWCntW/\nvZS8QPsPHx7o4L4KuMQ59z3v8bXAac65H7VYbhwwDmD48OGnbNhwYFpGXdnO6gb6FObF+7qD4Qi5\nOcastTs55VMDKMxL/7ZK9cEw1Q0hBvUuiE+rqg2Sn5tDD6/7orohRI+8APXBMD3yAq32LJxzmBl1\njWGWbalifUUNF405lL6FuWzaVcejM9ayuKySK44/jG+fEe27XLV9L5t21/HE++s49vB+nDi8PzkW\nPW18c2VdfB3+/bThLCmrIuLgwmMGU7qzllfnb2JI30KOGNCTi8YMIRRxPPthKccN60dJ6S769cjj\nojGHsmlXLb0LcjnN68b6qHQXh/Yt5IiBPakPhinbXcvgvoXUNoQ51LuBhnOOycuiu+N5gRxKK2ro\n1yMvPoY/Zs66nRTmBdhaWcem3bXsqQvxuaMO4XNHDgKi67GrppGX5m1kd20jXz35cM4YOYgNu2r4\n65wNbKms5/D+PRjSt4CThg+7nCtPAAAGeklEQVRg2IAeLNpUSf+e+bwwZwOXHncoPfJyKczL4fEZ\n6zhr1CDWllczb/0uIhHHyKLe9CnMZXdtI0cM6EluwOiRl8uQvgX0yA9w3tGDeXHeRrZU1lGYG+Bz\nRx1Cr/xcRg3pzeA+hfTID+Cc4+OyKhpDEU4dMZCZqyuoqG7g7E8X8dqCMnLM+NZpw5m9bicDeubz\n9Mz17Kpp5LrPFTNsQA/WV9QQDEf4qHQXOWZU1QUZfWhfjh/Wj3Xl1dQHI0z4YB2nFg/E4Th5+ABO\nH3kIU5Zvp7Siho/Lop+V844uoldBLgN75dMzP5djhvZh1proZ/nIwb0Yc1g//vD2SuqCIdbsqKZ0\nZy0NwTAXjzmU+lCEYChCWWUtfQry2F3byHmjB5ObY0ScY9OuOtaWVzNqcG9qGsMM6VtAbUOY0p01\nPHrNKQzoGd2uy7fuoaK6gYLcAGvLqzlpeH9qGsI0hMKs2VFN2e46brxgFEu3VPHc7A2U723gu2eN\nYOSgXqwtr2bGynLeXb6dot4FVNUFufmyY7jqlGFU1Qb51+ItrK+oYcxhfQlFov8P909ZhQFXHD+U\nV+dvZvShffjvi49O+++2qYwEd1PdocUtInIgtSe402nPbwaOaPJ4mDdNREQyIJ3g/ggYZWYjzCwf\n+Cbwz84tS0REkkk5HNA5FzKzHwGTiQ4HfNo5tyzF00REpJOkNY7bOfcWkN6ZJyIi0qm65SnvIiLZ\nTMEtIpJlFNwiIllGwS0ikmVSnoDToRc1Kwc6eurkICD77t6ZHq1b9urK66d184dPOeeK0lmwU4J7\nf5hZSbpnD2UbrVv26srrp3XLPuoqERHJMgpuEZEs48fgnpDpAjqR1i17deX107plGd/1cYuISNv8\n2OIWEZE2KLhFRLKMb4LbzC4xs5VmtsbMxme6nvYysyPMbJqZfWJmy8zsRm/6QDN718xWe/8O8Kab\nmT3kre9iMzs5s2uQHjMLmNlCM5voPR5hZnO99XjFu/QvZlbgPV7jzS/OZN2pmFl/M3vVzFaY2XIz\nO6OrbDszu8n7TC41s5fMrDCbt5uZPW1mO8xsaZNp7d5WZnadt/xqM7suE+vSUb4Ibu+GxA8DlwKf\nAa42s89ktqp2CwE/c859Bjgd+KG3DuOBqc65UcBU7zFE13WU9zMOePTgl9whNwJNb8H+e+B+59xR\nwG7gem/69cBub/r93nJ+9iDwtnNuNHAC0XXM+m1nZocD/wWMdc4dS/TSzN8ku7fbs8AlLaa1a1uZ\n2UDgN8BpwKnAb2JhnxWccxn/Ac4AJjd5fDNwc6br2s91+gfwBWAlMNSbNhRY6f3+OHB1k+Xjy/n1\nh+jdj6YC5wMTASN6Vlpuy+1I9PrtZ3i/53rLWabXIcl69QPWt6yvK2w74HBgEzDQ2w4TgYuzfbsB\nxcDSjm4r4Grg8SbTmy3n9x9ftLjZ9+GKKfOmZSVv9/IkYC4wxDm31Zu1DRji/Z6N6/wA8Asg4j0+\nBKh0zoW8x03XIb5+3vwqb3k/GgGUA8943UBPmlkvusC2c85tBu4FNgJbiW6H+XSN7dZUe7dV1mzD\nRPwS3F2GmfUG/g78xDm3p+k8F/1qz8rxl2Z2BbDDOTc/07V0glzgZOBR59xJQA37drWB7N123u7/\nl4h+OR0G9KJ1N0OXkq3bqj38Etxd4obEZpZHNLRfcM695k3ebmZDvflDgR3e9Gxb5zOBK82sFHiZ\naHfJg0B/M4vdSanpOsTXz5vfD9h5MAtuhzKgzDk313v8KtEg7wrb7kJgvXOu3DkXBF4jui27wnZr\nqr3bKpu2YSt+Ce6svyGxmRnwFLDcOXdfk1n/BGJHrK8j2vcdm/5t76j36UBVk10933HO3eycG+ac\nKya6fd5zzv07MA24ylus5frF1vsqb3lftoKcc9uATWZ2tDfpAuATusa22wicbmY9vc9obN2yfru1\n0N5tNRm4yMwGeHslF3nTskOmO9mbHBy4DFgFrAX+J9P1dKD+s4juni0GFnk/lxHtH5wKrAamAAO9\n5Y3oSJq1wBKiR/0zvh5pruu5wETv95HAPGAN8H9AgTe90Hu8xps/MtN1p1inE4ESb/u9AQzoKtsO\nuB1YASwFngcKsnm7AS8R7a8PEt1bur4j2wr4rreea4D/yPR6tedHp7yLiGQZv3SViIhImhTcIiJZ\nRsEtIpJlFNwiIllGwS0ikmUU3CIiWUbBLSKSZf4f3CXZajgvWdgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqugVRVGyHFX0iqIoWY4qekVRlCzn/wMskZ5tPbP3sgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rpGg9QcDQLSf",
        "colab_type": "code",
        "outputId": "77693688-a827-43e9-c8e7-9966328af4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.title('Training Loss')\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.figure(2)\n",
        "plt.title('Training Accuracies')\n",
        "plt.plot(range(len(validation_accuracies)), validation_accuracies,'-',range(len(train_accuracies)),train_accuracies,'.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqugVRVGyHFX0iqIoWY4qekVRlCzn/wMskZ5tPbP3sgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JyzxktOIal1U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}